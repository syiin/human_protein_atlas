{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Starter Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH = './'\n",
    "TRAIN = 'data/train/'\n",
    "TEST = 'data/test/'\n",
    "LABELS = 'data/train.csv'\n",
    "SAMPLE = 'data/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name_label_dict = {\n",
    "0:  'Nucleoplasm',\n",
    "1:  'Nuclear membrane',\n",
    "2:  'Nucleoli',   \n",
    "3:  'Nucleoli fibrillar center',\n",
    "4:  'Nuclear speckles',\n",
    "5:  'Nuclear bodies',\n",
    "6:  'Endoplasmic reticulum',   \n",
    "7:  'Golgi apparatus',\n",
    "8:  'Peroxisomes',\n",
    "9:  'Endosomes',\n",
    "10:  'Lysosomes',\n",
    "11:  'Intermediate filaments',\n",
    "12:  'Actin filaments',\n",
    "13:  'Focal adhesion sites',   \n",
    "14:  'Microtubules',\n",
    "15:  'Microtubule ends',  \n",
    "16:  'Cytokinetic bridge',   \n",
    "17:  'Mitotic spindle',\n",
    "18:  'Microtubule organizing center',  \n",
    "19:  'Centrosome',\n",
    "20:  'Lipid droplets',\n",
    "21:  'Plasma membrane',   \n",
    "22:  'Cell junctions', \n",
    "23:  'Mitochondria',\n",
    "24:  'Aggresome',\n",
    "25:  'Cytosol',\n",
    "26:  'Cytoplasmic bodies',   \n",
    "27:  'Rods & rings' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arch = resnet50\n",
    "nw=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_names = list({f[:36] for f in os.listdir(TRAIN)})\n",
    "test_names = list({f[:36] for f in os.listdir(TEST)})\n",
    "tr_n, val_n = train_test_split(train_names, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def open_rgby(path,id): \n",
    "    colors = ['red','green','blue','yellow']\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    img = [cv2.imread(os.path.join(path, id+'_'+color+'.png'), flags).astype(np.float32)/255\n",
    "           for color in colors]\n",
    "    return np.stack(img, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class pdFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, path, transform):\n",
    "        self.labels = pd.read_csv(LABELS).set_index('Id')\n",
    "        self.labels['Target'] = [[int(i) for i in s.split()] for s in self.labels['Target']]\n",
    "        super().__init__(fnames, transform, path)\n",
    "    \n",
    "    def get_x(self, i):\n",
    "        img = open_rgby(self.path,self.fnames[i])\n",
    "        if self.sz == 512: return img \n",
    "        else: return cv2.resize(img, (self.sz, self.sz),cv2.INTER_AREA)\n",
    "    \n",
    "    def get_y(self, i):\n",
    "        if(self.path == TEST): return np.zeros(len(name_label_dict),dtype=np.int)\n",
    "        else:\n",
    "            labels = self.labels.loc[self.fnames[i]]['Target']\n",
    "            return np.eye(len(name_label_dict),dtype=np.float)[labels].sum(axis=0)\n",
    "        \n",
    "    @property\n",
    "    def is_multi(self): return True\n",
    "    @property\n",
    "    def is_reg(self):return True\n",
    "    #this flag is set to remove the output sigmoid that allows log(sigmoid) optimization\n",
    "    #of the numerical stability of the loss function\n",
    "    \n",
    "    def get_c(self): return len(name_label_dict) #number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data(sz,bs):\n",
    "    #data augmentation\n",
    "    aug_tfms = [RandomRotate(30, tfm_y=TfmType.NO),\n",
    "                RandomDihedral(tfm_y=TfmType.NO)]\n",
    "    stats = A([0.00505, 0.00331, 0.00344, 0.00519], [0.10038, 0.08131, 0.08284, 0.10179])\n",
    "    tfms = tfms_from_stats(stats, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, \n",
    "                aug_tfms=aug_tfms)\n",
    "    ds = ImageData.get_ds(pdFilesDataset, (tr_n[:-(len(tr_n)%bs)],TRAIN), \n",
    "                (val_n,TRAIN), tfms, test=(test_names,TEST))\n",
    "    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 4, 256, 256]), torch.Size([16, 28]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "sz = 256\n",
    "md = get_data(sz,bs)\n",
    "\n",
    "x,y = next(iter(md.trn_dl))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def acc(preds,targs,thresh=0.0):\n",
    "    preds = (preds > thresh).int()\n",
    "    targs = targs.int()\n",
    "    return (preds==targs).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Model Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Convnet Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ConvnetBuilder_custom():\n",
    "    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, \n",
    "                 custom_head=None, pretrained=True):\n",
    "        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n",
    "        if xtra_fc is None: xtra_fc = [512]\n",
    "        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n",
    "        self.ps,self.xtra_fc = ps,xtra_fc\n",
    "\n",
    "        if f in model_meta: cut,self.lr_cut = model_meta[f]\n",
    "        else: cut,self.lr_cut = 0,0\n",
    "        cut-=xtra_cut\n",
    "        layers = cut_model(f(pretrained), cut)\n",
    "        \n",
    "        #replace first convolutional layer by 4->64 while keeping corresponding weights\n",
    "        #and initializing new weights with zeros\n",
    "        #####################################################\n",
    "        w = layers[0].weight\n",
    "        layers[0] = nn.Conv2d(4,64,kernel_size=(7,7),stride=(2,2),padding=(3, 3), bias=False)\n",
    "        layers[0].weight = torch.nn.Parameter(torch.cat((w,torch.zeros(64,1,7,7)),dim=1))\n",
    "        #####################################################\n",
    "        \n",
    "        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n",
    "        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n",
    "        self.top_model = nn.Sequential(*layers)\n",
    "\n",
    "        n_fc = len(self.xtra_fc)+1\n",
    "        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n",
    "\n",
    "        if custom_head: fc_layers = [custom_head]\n",
    "        else: fc_layers = self.get_fc_layers()\n",
    "        self.n_fc = len(fc_layers)\n",
    "        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n",
    "        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n",
    "        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))\n",
    "\n",
    "    @property\n",
    "    def name(self): return f'{self.f.__name__}_{self.xtra_cut}'\n",
    "\n",
    "    def create_fc_layer(self, ni, nf, p, actn=None):\n",
    "        res=[nn.BatchNorm1d(num_features=ni)]\n",
    "        if p: res.append(nn.Dropout(p=p))\n",
    "        res.append(nn.Linear(in_features=ni, out_features=nf))\n",
    "        if actn: res.append(actn)\n",
    "        return res\n",
    "\n",
    "    def get_fc_layers(self):\n",
    "        res=[]\n",
    "        ni=self.nf\n",
    "        for i,nf in enumerate(self.xtra_fc):\n",
    "            res += self.create_fc_layer(ni, nf, p=self.ps[i], actn=nn.ReLU())\n",
    "            ni=nf\n",
    "        final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax()\n",
    "        if self.is_reg: final_actn = None\n",
    "        res += self.create_fc_layer(ni, self.c, p=self.ps[-1], actn=final_actn)\n",
    "        return res\n",
    "\n",
    "    def get_layer_groups(self, do_fc=False):\n",
    "        if do_fc:\n",
    "            return [self.fc_model]\n",
    "        idxs = [self.lr_cut]\n",
    "        c = children(self.top_model)\n",
    "        if len(c)==3: c = children(c[0])+c[1:]\n",
    "        lgs = list(split_by_idxs(c,idxs))\n",
    "        return lgs+[self.fc_model]\n",
    "    \n",
    "class ConvLearner(Learner):\n",
    "    def __init__(self, data, models, precompute=False, **kwargs):\n",
    "        self.precompute = False\n",
    "        super().__init__(data, models, **kwargs)\n",
    "        if hasattr(data, 'is_multi') and not data.is_reg and self.metrics is None:\n",
    "            self.metrics = [accuracy_thresh(0.5)] if self.data.is_multi else [accuracy]\n",
    "        if precompute: self.save_fc1()\n",
    "        self.freeze()\n",
    "        self.precompute = precompute\n",
    "\n",
    "    def _get_crit(self, data):\n",
    "        if not hasattr(data, 'is_multi'): return super()._get_crit(data)\n",
    "\n",
    "        return F.l1_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n",
    "\n",
    "    @classmethod\n",
    "    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n",
    "                   pretrained=True, **kwargs):\n",
    "        models = ConvnetBuilder_custom(f, data.c, data.is_multi, data.is_reg,\n",
    "            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n",
    "        return cls(data, models, precompute, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def lsuv_learner(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n",
    "                  needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False, **kwargs):\n",
    "        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n",
    "            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=False)\n",
    "        convlearn=cls(data, models, precompute, **kwargs)\n",
    "        convlearn.lsuv_init()\n",
    "        return convlearn\n",
    "    \n",
    "    @property\n",
    "    def model(self): return self.models.fc_model if self.precompute else self.models.model\n",
    "    \n",
    "    def half(self):\n",
    "        if self.fp16: return\n",
    "        self.fp16 = True\n",
    "        if type(self.model) != FP16: self.models.model = FP16(self.model)\n",
    "        if not isinstance(self.models.fc_model, FP16): self.models.fc_model = FP16(self.models.fc_model)\n",
    "    def float(self):\n",
    "        if not self.fp16: return\n",
    "        self.fp16 = False\n",
    "        if type(self.models.model) == FP16: self.models.model = self.model.module.float()\n",
    "        if type(self.models.fc_model) == FP16: self.models.fc_model = self.models.fc_model.module.float()\n",
    "\n",
    "    @property\n",
    "    def data(self): return self.fc_data if self.precompute else self.data_\n",
    "\n",
    "    def create_empty_bcolz(self, n, name):\n",
    "        return bcolz.carray(np.zeros((0,n), np.float32), chunklen=1, mode='w', rootdir=name)\n",
    "\n",
    "    def set_data(self, data, precompute=False):\n",
    "        super().set_data(data)\n",
    "        if precompute:\n",
    "            self.unfreeze()\n",
    "            self.save_fc1()\n",
    "            self.freeze()\n",
    "            self.precompute = True\n",
    "        else:\n",
    "            self.freeze()\n",
    "\n",
    "    def get_layer_groups(self):\n",
    "        return self.models.get_layer_groups(self.precompute)\n",
    "\n",
    "    def summary(self):\n",
    "        precompute = self.precompute\n",
    "        self.precompute = False\n",
    "        res = super().summary()\n",
    "        self.precompute = precompute\n",
    "        return res\n",
    "\n",
    "    def get_activations(self, force=False):\n",
    "        tmpl = f'_{self.models.name}_{self.data.sz}.bc'\n",
    "        # TODO: Somehow check that directory names haven't changed (e.g. added test set)\n",
    "        names = [os.path.join(self.tmp_path, p+tmpl) for p in ('x_act', 'x_act_val', 'x_act_test')]\n",
    "        if os.path.exists(names[0]) and not force:\n",
    "            self.activations = [bcolz.open(p) for p in names]\n",
    "        else:\n",
    "            self.activations = [self.create_empty_bcolz(self.models.nf,n) for n in names]\n",
    "\n",
    "    def save_fc1(self):\n",
    "        self.get_activations()\n",
    "        act, val_act, test_act = self.activations\n",
    "        m=self.models.top_model\n",
    "        if len(self.activations[0])!=len(self.data.trn_ds):\n",
    "            predict_to_bcolz(m, self.data.fix_dl, act)\n",
    "        if len(self.activations[1])!=len(self.data.val_ds):\n",
    "            predict_to_bcolz(m, self.data.val_dl, val_act)\n",
    "        if self.data.test_dl and (len(self.activations[2])!=len(self.data.test_ds)):\n",
    "            if self.data.test_dl: predict_to_bcolz(m, self.data.test_dl, test_act)\n",
    "\n",
    "        self.fc_data = ImageClassifierData.from_arrays(self.data.path,\n",
    "                (act, self.data.trn_y), (val_act, self.data.val_y), self.data.bs, classes=self.data.classes,\n",
    "                test = test_act if self.data.test_dl else None, num_workers=8)\n",
    "\n",
    "    def freeze(self):\n",
    "        self.freeze_to(-1)\n",
    "\n",
    "    def unfreeze(self):\n",
    "        self.freeze_to(0)\n",
    "        self.precompute = False\n",
    "\n",
    "    def predict_array(self, arr):\n",
    "        precompute = self.precompute\n",
    "        self.precompute = False\n",
    "        pred = super().predict_array(arr)\n",
    "        self.precompute = precompute\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model(md):\n",
    "    learn = ConvLearner.pretrained(arch, md, ps=0.5) #dropout 50%\n",
    "    learn.opt_fn = optim.Adam\n",
    "    learn.crit = FocalLoss()\n",
    "    learn.metrics = [acc]\n",
    "    return learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Inception v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ConvnetBuilder_Inv4(ConvnetBuilder_custom):\n",
    "    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, \n",
    "                 custom_head=None, pretrained=True):\n",
    "        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n",
    "        if xtra_fc is None: xtra_fc = [512]\n",
    "        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n",
    "        self.ps,self.xtra_fc = ps,xtra_fc\n",
    "\n",
    "        if f in model_meta: cut,self.lr_cut = model_meta[f]\n",
    "        else: cut,self.lr_cut = 0,0\n",
    "        cut-=xtra_cut\n",
    "        layers = cut_model(f(pretrained), cut)\n",
    "        \n",
    "        #replace first convolutional layer by 4->64 while keeping corresponding weights\n",
    "        #and initializing new weights with zeros\n",
    "        w = layers[0].conv.weight\n",
    "        layers[0] = nn.Conv2d(4,32,kernel_size=(3,3),stride=(2,2))\n",
    "        layers[0].weight = torch.nn.Parameter(torch.cat((w,torch.zeros(32,1,3,3)),dim=1))\n",
    "        \n",
    "        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n",
    "        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n",
    "        self.top_model = nn.Sequential(*layers)\n",
    "\n",
    "        n_fc = len(self.xtra_fc)+1\n",
    "        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n",
    "\n",
    "        if custom_head: fc_layers = [custom_head]\n",
    "        else: fc_layers = self.get_fc_layers()\n",
    "        self.n_fc = len(fc_layers)\n",
    "        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n",
    "        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n",
    "        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class InceptLearner(ConvLearner):\n",
    "    @classmethod\n",
    "    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n",
    "                   pretrained=True, **kwargs):\n",
    "        models = ConvnetBuilder_Inv4(f, data.c, data.is_multi, data.is_reg,\n",
    "            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n",
    "        return cls(data, models, precompute, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_inceptv4(md):\n",
    "    learn = InceptLearner.pretrained(inception_4, md, ps=0.5) #dropout 50%\n",
    "    learn.opt_fn = optim.Adam\n",
    "    learn.crit = FocalLoss()\n",
    "    learn.metrics = [acc]\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def my_load_pre(pre, f, fn):\n",
    "    m = f()\n",
    "    if pre: load_model(m, f'weights/{fn}.pth')\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def my_resnext50(pre): return my_load_pre(pre, resnext_50_32x4d, 'resnext_50_32x4d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ResNextBuilder(ConvnetBuilder_custom):\n",
    "    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, \n",
    "                 custom_head=None, pretrained=True):\n",
    "        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n",
    "        if xtra_fc is None: xtra_fc = [512]\n",
    "        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n",
    "        self.ps,self.xtra_fc = ps,xtra_fc\n",
    "\n",
    "        if f in model_meta: cut,self.lr_cut = model_meta[f]\n",
    "        else: cut,self.lr_cut = 0,0\n",
    "        cut-=xtra_cut\n",
    "        #change this to 8 hard coded\n",
    "        layers = cut_model(f(pretrained), 8)\n",
    "        \n",
    "        #replace first convolutional layer by 4->64 while keeping corresponding weights\n",
    "        #and initializing new weights with zeros\n",
    "        w = layers[0].weight\n",
    "        layers[0] = nn.Conv2d(4,64,kernel_size=(7,7),stride=(2,2),padding=(3, 3), bias=False)\n",
    "        layers[0].weight = torch.nn.Parameter(torch.cat((w,torch.zeros(64,1,7,7)),dim=1))\n",
    "        \n",
    "        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n",
    "        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n",
    "        self.top_model = nn.Sequential(*layers)\n",
    "\n",
    "        n_fc = len(self.xtra_fc)+1\n",
    "        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n",
    "\n",
    "        if custom_head: fc_layers = [custom_head]\n",
    "        else: fc_layers = self.get_fc_layers()\n",
    "        self.n_fc = len(fc_layers)\n",
    "        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n",
    "        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n",
    "        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ResNextLearner(ConvLearner):\n",
    "    @classmethod\n",
    "    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n",
    "                   pretrained=True, **kwargs):\n",
    "        models = ResNextBuilder(f, data.c, data.is_multi, data.is_reg,\n",
    "            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n",
    "        return cls(data, models, precompute, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_resnext50(md):\n",
    "    learn = ResNextLearner.pretrained(my_resnext50, md, ps=0.5) #dropout 50%\n",
    "    learn.opt_fn = optim.Adam\n",
    "    learn.crit = FocalLoss()\n",
    "    learn.metrics = [acc]\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_resnext50(md):\n",
    "    learn = ConvLearner.pretrained(resnext50, md, ps=0.5) #dropout 50%\n",
    "    learn.opt_fn = optim.Adam\n",
    "    learn.crit = FocalLoss()\n",
    "    learn.metrics = [acc]\n",
    "    return learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    }
   ],
   "source": [
    "sz = 512 #image size\n",
    "bs = 16  #batch size\n",
    "\n",
    "md = get_data(sz,bs)\n",
    "learn = get_model(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "phase = 1\n",
    "learn.unfreeze()\n",
    "lrs=np.array([lr/10,lr/3,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7ea273a4f84c3eac36c00f13f2cea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.891387   0.800228   0.963045  \n",
      "    1      0.735691   0.675827   0.967722                      \n",
      "    2      0.793446   0.75091    0.965354                      \n",
      "    3      0.719411   0.614211   0.970479                      \n",
      "    4      0.764894   0.675408   0.968158                      \n",
      "    5      0.659164   0.596702   0.972008                      \n",
      "    6      0.762538   0.67676    0.967928                      \n",
      "    7      0.632455   0.581715   0.972548                      \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5817154650522475, 0.9725478046802634]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/4,4,cycle_len=2,use_clr=(10,20), best_save_name=f'{arch}_{phase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "phase = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1eace817d5a426cb4678099702bcd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.714727   0.727787   0.966308  \n",
      "    1      0.724831   0.660549   0.968986                      \n",
      "    2      0.723787   0.660595   0.969009                      \n",
      "    3      0.70075    0.623011   0.97041                       \n",
      "    4      0.682225   0.647125   0.969687                      \n",
      "    5      0.664514   0.625572   0.970479                      \n",
      "    6      0.670425   0.610064   0.971732                      \n",
      "    7      0.634118   0.58965    0.9721                        \n",
      "    8      0.614346   0.591748   0.972065                      \n",
      "    9      0.623502   0.575815   0.97218                       \n",
      "    10     0.617414   0.572454   0.973329                      \n",
      "    11     0.593472   0.562013   0.973915                      \n",
      "    12     0.584679   0.556153   0.973502                      \n",
      "    13     0.594047   0.559913   0.973548                      \n",
      "    14     0.554874   0.543421   0.973846                      \n",
      "    15     0.533736   0.53982    0.974501                      \n",
      "    16     0.563146   0.549019   0.973881                      \n",
      "    17     0.521663   0.53013    0.974754                      \n",
      "    18     0.540076   0.522106   0.97488                       \n",
      "    19     0.499335   0.520245   0.974961                      \n",
      "    20     0.506516   0.515602   0.975444                      \n",
      "    21     0.475341   0.51225    0.975892                      \n",
      "    22     0.500185   0.506745   0.976018                      \n",
      "    23     0.578823   0.5923     0.971973                      \n",
      "    24     0.603353   0.589917   0.972536                      \n",
      "    25     0.618475   0.611372   0.970571                      \n",
      "    26     0.586156   0.555191   0.973662                      \n",
      "    27     0.62202    0.574747   0.972766                      \n",
      "    28     0.572086   0.558352   0.973789                      \n",
      "    29     0.573628   0.568104   0.97303                       \n",
      "    30     0.565333   0.561526   0.973616                      \n",
      "    31     0.547398   0.534598   0.974949                      \n",
      "    32     0.538767   0.537666   0.974157                      \n",
      "    33     0.532834   0.539421   0.974559                      \n",
      "    34     0.537303   0.536572   0.97488                       \n",
      "    35     0.509458   0.522482   0.975363                      \n",
      "    36     0.504854   0.513693   0.975558                      \n",
      "    37     0.475108   0.512101   0.97619                       \n",
      "    38     0.46561    0.515727   0.975386                      \n",
      "    39     0.473609   0.505854   0.975788                      \n",
      "    40     0.444643   0.517803   0.975535                      \n",
      "    41     0.41677    0.506221   0.976099                      \n",
      "    42     0.409577   0.497479   0.976731                      \n",
      "    43     0.422281   0.504476   0.97665                       \n",
      "    44     0.390652   0.497793   0.976811                      \n",
      "    45     0.399262   0.493514   0.976845                      \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4935136167776017, 0.9768454665689702]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/4,2,cycle_len=23,use_clr=(10,20), best_save_name=f'{arch}_{phase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "phase = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03135d5659cc4f81b5b347b42a81eac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.432474   0.50745    0.976099  \n",
      "    1      0.461577   0.512838   0.976087                      \n",
      "    2      0.444551   0.525572   0.976213                      \n",
      "    3      0.430047   0.506457   0.97611                       \n",
      "    4      0.416674   0.514185   0.976765                      \n",
      "    5      0.424571   0.506176   0.976466                      \n",
      "    6      0.394757   0.508665   0.976972                      \n",
      "    7      0.379364   0.514699   0.977213                      \n",
      "    8      0.363523   0.51059    0.977305                      \n",
      "    9      0.369209   0.508859   0.977569                      \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5088593657566006, 0.9775694077846473]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/8,1,cycle_len=10,use_clr=(5,20), best_save_name=f'{arch}_{phase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "phase = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841ab9c0ed2c4bfe85780e2d45eaaa90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.369432   0.509641   0.976926  \n",
      "    1      0.358003   0.529455   0.976719                      \n",
      "    2      0.347245   0.517453   0.977742                      \n",
      "    3      0.349706   0.525909   0.977604                      \n",
      "    4      0.36438    0.512965   0.9775                        \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5129647924249543, 0.9775004624706745]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/20,1,cycle_len=5,use_clr=(5,20), best_save_name=f'{arch}_{phase}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNext50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### House Keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './'\n",
    "TRAIN = 'data/train/'\n",
    "TEST = 'data/test/'\n",
    "LABELS = 'data/train.csv'\n",
    "SAMPLE = 'data/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = list({f[:36] for f in os.listdir(TRAIN)})\n",
    "test_names = list({f[:36] for f in os.listdir(TEST)})\n",
    "tr_n, val_n = train_test_split(train_names, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_rgby(path,id): \n",
    "    colors = ['red','green','blue','yellow']\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    img = [cv2.imread(os.path.join(path, id+'_'+color+'.png'), flags).astype(np.float32)/255\n",
    "           for color in colors]\n",
    "    return np.stack(img, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_label_dict = {\n",
    "0:  'Nucleoplasm',\n",
    "1:  'Nuclear membrane',\n",
    "2:  'Nucleoli',   \n",
    "3:  'Nucleoli fibrillar center',\n",
    "4:  'Nuclear speckles',\n",
    "5:  'Nuclear bodies',\n",
    "6:  'Endoplasmic reticulum',   \n",
    "7:  'Golgi apparatus',\n",
    "8:  'Peroxisomes',\n",
    "9:  'Endosomes',\n",
    "10:  'Lysosomes',\n",
    "11:  'Intermediate filaments',\n",
    "12:  'Actin filaments',\n",
    "13:  'Focal adhesion sites',   \n",
    "14:  'Microtubules',\n",
    "15:  'Microtubule ends',  \n",
    "16:  'Cytokinetic bridge',   \n",
    "17:  'Mitotic spindle',\n",
    "18:  'Microtubule organizing center',  \n",
    "19:  'Centrosome',\n",
    "20:  'Lipid droplets',\n",
    "21:  'Plasma membrane',   \n",
    "22:  'Cell junctions', \n",
    "23:  'Mitochondria',\n",
    "24:  'Aggresome',\n",
    "25:  'Cytosol',\n",
    "26:  'Cytoplasmic bodies',   \n",
    "27:  'Rods & rings' }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Objects & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pdFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, path, transform):\n",
    "        self.labels = pd.read_csv(LABELS).set_index('Id')\n",
    "        self.labels['Target'] = [[int(i) for i in s.split()] for s in self.labels['Target']]\n",
    "        super().__init__(fnames, transform, path)\n",
    "    \n",
    "    def get_x(self, i):\n",
    "        img = open_rgby(self.path,self.fnames[i])\n",
    "        if self.sz == 512: return img \n",
    "        else: return cv2.resize(img, (self.sz, self.sz),cv2.INTER_AREA)\n",
    "    \n",
    "    def get_y(self, i):\n",
    "        if(self.path == TEST): return np.zeros(len(name_label_dict),dtype=np.int)\n",
    "        else:\n",
    "            labels = self.labels.loc[self.fnames[i]]['Target']\n",
    "            return np.eye(len(name_label_dict),dtype=np.float)[labels].sum(axis=0)\n",
    "        \n",
    "    @property\n",
    "    def is_multi(self): return True\n",
    "    @property\n",
    "    def is_reg(self):return True\n",
    "    #this flag is set to remove the output sigmoid that allows log(sigmoid) optimization\n",
    "    #of the numerical stability of the loss function\n",
    "    \n",
    "    def get_c(self): return len(name_label_dict) #number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz,bs):\n",
    "    #data augmentation\n",
    "    aug_tfms = [RandomRotate(30, tfm_y=TfmType.NO),\n",
    "                RandomDihedral(tfm_y=TfmType.NO)]\n",
    "    stats = A([0.00505, 0.00331, 0.00344, 0.00519], [0.10038, 0.08131, 0.08284, 0.10179])\n",
    "    tfms = tfms_from_stats(stats, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, \n",
    "                aug_tfms=aug_tfms)\n",
    "    ds = ImageData.get_ds(pdFilesDataset, (tr_n[:-(len(tr_n)%bs)],TRAIN), \n",
    "                (val_n,TRAIN), tfms, test=(test_names,TEST))\n",
    "    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCalculating the averages\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Calculating the averages\n",
    "'''\n",
    "\n",
    "# x_tot = np.zeros(4)\n",
    "# x2_tot = np.zeros(4)\n",
    "# for x,y in iter(md.trn_dl):\n",
    "#     tmp =  md.trn_ds.denorm(x).reshape(16,-1)\n",
    "#     x = md.trn_ds.denorm(x).reshape(-1,4)\n",
    "#     x_tot += x.mean(axis=0)\n",
    "#     x2_tot += (x**2).mean(axis=0)\n",
    "\n",
    "# channel_avr = x_tot/len(md.trn_dl)\n",
    "# channel_std = np.sqrt(x2_tot/len(md.trn_dl) - channel_avr**2)\n",
    "# channel_avr,channel_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()\n",
    "    \n",
    "def acc(preds,targs,thresh=0.0):\n",
    "    preds = (preds > thresh).int()\n",
    "    targs = targs.int()\n",
    "    return (preds==targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, num_classes=28):\n",
    "#         super().__init__()\n",
    "#         self.num_classes = num_classes\n",
    "\n",
    "#     def forward(self, pred, targ):\n",
    "#         t = targ\n",
    "#         x = pred\n",
    "#         w = self.get_weight(x,t)\n",
    "#         return F.binary_cross_entropy_with_logits(x, t, w, \n",
    "#                           reduction='none')/self.num_classes\n",
    "    \n",
    "#     def get_weight(self,x,t):\n",
    "#         alpha,gamma = 0.25,2.\n",
    "#         p = x.sigmoid()\n",
    "#         pt = p*t + (1-p)*(1-t)\n",
    "#         w = alpha*t + (1-alpha)*(1-t)\n",
    "#         return w * (1-pt).pow(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvnetBuilder_custom():\n",
    "    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, \n",
    "                 custom_head=None, pretrained=True):\n",
    "        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n",
    "        if xtra_fc is None: xtra_fc = [512]\n",
    "        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n",
    "        self.ps,self.xtra_fc = ps,xtra_fc\n",
    "\n",
    "        if f in model_meta: cut,self.lr_cut = model_meta[f]\n",
    "        else: cut,self.lr_cut = 0,0\n",
    "        cut-=xtra_cut\n",
    "        layers = cut_model(f(pretrained), cut)\n",
    "        \n",
    "        #replace first convolutional layer by 4->64 while keeping corresponding weights\n",
    "        #and initializing new weights with zeros\n",
    "        #####################################################\n",
    "        w = layers[0].weight\n",
    "        layers[0] = nn.Conv2d(4,64,kernel_size=(7,7),stride=(2,2),padding=(3, 3), bias=False)\n",
    "        layers[0].weight = torch.nn.Parameter(torch.cat((w,torch.zeros(64,1,7,7)),dim=1))\n",
    "        #####################################################\n",
    "        \n",
    "        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n",
    "        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n",
    "        self.top_model = nn.Sequential(*layers)\n",
    "\n",
    "        n_fc = len(self.xtra_fc)+1\n",
    "        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n",
    "\n",
    "        if custom_head: fc_layers = [custom_head]\n",
    "        else: fc_layers = self.get_fc_layers()\n",
    "        self.n_fc = len(fc_layers)\n",
    "        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n",
    "        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n",
    "        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))\n",
    "\n",
    "    @property\n",
    "    def name(self): return f'{self.f.__name__}_{self.xtra_cut}'\n",
    "\n",
    "    def create_fc_layer(self, ni, nf, p, actn=None):\n",
    "        res=[nn.BatchNorm1d(num_features=ni)]\n",
    "        if p: res.append(nn.Dropout(p=p))\n",
    "        res.append(nn.Linear(in_features=ni, out_features=nf))\n",
    "        if actn: res.append(actn)\n",
    "        return res\n",
    "\n",
    "    def get_fc_layers(self):\n",
    "        res=[]\n",
    "        ni=self.nf\n",
    "        for i,nf in enumerate(self.xtra_fc):\n",
    "            res += self.create_fc_layer(ni, nf, p=self.ps[i], actn=nn.ReLU())\n",
    "            ni=nf\n",
    "        final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax()\n",
    "        if self.is_reg: final_actn = None\n",
    "        res += self.create_fc_layer(ni, self.c, p=self.ps[-1], actn=final_actn)\n",
    "        return res\n",
    "\n",
    "    def get_layer_groups(self, do_fc=False):\n",
    "        if do_fc:\n",
    "            return [self.fc_model]\n",
    "        idxs = [self.lr_cut]\n",
    "        c = children(self.top_model)\n",
    "        if len(c)==3: c = children(c[0])+c[1:]\n",
    "        lgs = list(split_by_idxs(c,idxs))\n",
    "        return lgs+[self.fc_model]\n",
    "    \n",
    "class ConvLearner(Learner):\n",
    "    def __init__(self, data, models, precompute=False, **kwargs):\n",
    "        self.precompute = False\n",
    "        super().__init__(data, models, **kwargs)\n",
    "        if hasattr(data, 'is_multi') and not data.is_reg and self.metrics is None:\n",
    "            self.metrics = [accuracy_thresh(0.5)] if self.data.is_multi else [accuracy]\n",
    "        if precompute: self.save_fc1()\n",
    "        self.freeze()\n",
    "        self.precompute = precompute\n",
    "\n",
    "    def _get_crit(self, data):\n",
    "        if not hasattr(data, 'is_multi'): return super()._get_crit(data)\n",
    "\n",
    "        return F.l1_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n",
    "\n",
    "    @classmethod\n",
    "    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n",
    "                   pretrained=True, **kwargs):\n",
    "        models = ConvnetBuilder_custom(f, data.c, data.is_multi, data.is_reg,\n",
    "            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n",
    "        return cls(data, models, precompute, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def lsuv_learner(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n",
    "                  needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False, **kwargs):\n",
    "        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n",
    "            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=False)\n",
    "        convlearn=cls(data, models, precompute, **kwargs)\n",
    "        convlearn.lsuv_init()\n",
    "        return convlearn\n",
    "    \n",
    "    @property\n",
    "    def model(self): return self.models.fc_model if self.precompute else self.models.model\n",
    "    \n",
    "    def half(self):\n",
    "        if self.fp16: return\n",
    "        self.fp16 = True\n",
    "        if type(self.model) != FP16: self.models.model = FP16(self.model)\n",
    "        if not isinstance(self.models.fc_model, FP16): self.models.fc_model = FP16(self.models.fc_model)\n",
    "    def float(self):\n",
    "        if not self.fp16: return\n",
    "        self.fp16 = False\n",
    "        if type(self.models.model) == FP16: self.models.model = self.model.module.float()\n",
    "        if type(self.models.fc_model) == FP16: self.models.fc_model = self.models.fc_model.module.float()\n",
    "\n",
    "    @property\n",
    "    def data(self): return self.fc_data if self.precompute else self.data_\n",
    "\n",
    "    def create_empty_bcolz(self, n, name):\n",
    "        return bcolz.carray(np.zeros((0,n), np.float32), chunklen=1, mode='w', rootdir=name)\n",
    "\n",
    "    def set_data(self, data, precompute=False):\n",
    "        super().set_data(data)\n",
    "        if precompute:\n",
    "            self.unfreeze()\n",
    "            self.save_fc1()\n",
    "            self.freeze()\n",
    "            self.precompute = True\n",
    "        else:\n",
    "            self.freeze()\n",
    "\n",
    "    def get_layer_groups(self):\n",
    "        return self.models.get_layer_groups(self.precompute)\n",
    "\n",
    "    def summary(self):\n",
    "        precompute = self.precompute\n",
    "        self.precompute = False\n",
    "        res = super().summary()\n",
    "        self.precompute = precompute\n",
    "        return res\n",
    "\n",
    "    def get_activations(self, force=False):\n",
    "        tmpl = f'_{self.models.name}_{self.data.sz}.bc'\n",
    "        # TODO: Somehow check that directory names haven't changed (e.g. added test set)\n",
    "        names = [os.path.join(self.tmp_path, p+tmpl) for p in ('x_act', 'x_act_val', 'x_act_test')]\n",
    "        if os.path.exists(names[0]) and not force:\n",
    "            self.activations = [bcolz.open(p) for p in names]\n",
    "        else:\n",
    "            self.activations = [self.create_empty_bcolz(self.models.nf,n) for n in names]\n",
    "\n",
    "    def save_fc1(self):\n",
    "        self.get_activations()\n",
    "        act, val_act, test_act = self.activations\n",
    "        m=self.models.top_model\n",
    "        if len(self.activations[0])!=len(self.data.trn_ds):\n",
    "            predict_to_bcolz(m, self.data.fix_dl, act)\n",
    "        if len(self.activations[1])!=len(self.data.val_ds):\n",
    "            predict_to_bcolz(m, self.data.val_dl, val_act)\n",
    "        if self.data.test_dl and (len(self.activations[2])!=len(self.data.test_ds)):\n",
    "            if self.data.test_dl: predict_to_bcolz(m, self.data.test_dl, test_act)\n",
    "\n",
    "        self.fc_data = ImageClassifierData.from_arrays(self.data.path,\n",
    "                (act, self.data.trn_y), (val_act, self.data.val_y), self.data.bs, classes=self.data.classes,\n",
    "                test = test_act if self.data.test_dl else None, num_workers=8)\n",
    "\n",
    "    def freeze(self):\n",
    "        self.freeze_to(-1)\n",
    "\n",
    "    def unfreeze(self):\n",
    "        self.freeze_to(0)\n",
    "        self.precompute = False\n",
    "\n",
    "    def predict_array(self, arr):\n",
    "        precompute = self.precompute\n",
    "        self.precompute = False\n",
    "        pred = super().predict_array(arr)\n",
    "        self.precompute = precompute\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SE Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_settings = {\n",
    "    'se_resnext50_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext101_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    Bottleneck for SENet154.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
    "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
    "    (the latter is used in the torchvision implementation of ResNet).\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
    "                               stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
    "                               groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SENet(nn.Module):\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.5,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "#         self.last_linear = nn.Linear(512*16, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def initialize_pretrained_model(model, num_classes, settings):\n",
    "    assert num_classes == settings['num_classes'], \\\n",
    "        'num_classes should be {}, but is {}'.format(\n",
    "            settings['num_classes'], num_classes)\n",
    "    model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "    model.input_space = settings['input_space']\n",
    "    model.input_size = settings['input_size']\n",
    "    model.input_range = settings['input_range']\n",
    "    model.mean = settings['mean']\n",
    "    model.std = settings['std']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNextConvBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNextConvBuilder(ConvnetBuilder_custom):\n",
    "    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, \n",
    "                 custom_head=None, pretrained=True):\n",
    "        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n",
    "        if xtra_fc is None: xtra_fc = [512]\n",
    "        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n",
    "        self.ps,self.xtra_fc = ps,xtra_fc\n",
    "\n",
    "        if f in model_meta: cut,self.lr_cut = model_meta[f]\n",
    "        else: cut,self.lr_cut = 8,6\n",
    "        cut-=xtra_cut\n",
    "        layers = cut_model(f(), 5)\n",
    "#         layers = cut_model(f(), 6)\n",
    "        \n",
    "        #replace first convolutional layer by 4->64 while keeping corresponding weights\n",
    "        #and initializing new weights with zeros\n",
    "        #####################################################\n",
    "        w = layers[0].conv1.weight\n",
    "        layers[0].conv1 = nn.Conv2d(4,64,kernel_size=(7,7),stride=(2,2),padding=(3, 3), bias=False)\n",
    "        layers[0].conv1.weight = torch.nn.Parameter(torch.cat((w,torch.zeros(64,1,7,7)),dim=1))\n",
    "        #####################################################\n",
    "        \n",
    "        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n",
    "        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n",
    "        self.top_model = nn.Sequential(*layers)\n",
    "\n",
    "        n_fc = len(self.xtra_fc)+1\n",
    "        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n",
    "\n",
    "        if custom_head: fc_layers = [custom_head]\n",
    "        else: fc_layers = self.get_fc_layers()\n",
    "        self.n_fc = len(fc_layers)\n",
    "        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n",
    "        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n",
    "        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))\n",
    "\n",
    "class ResNextConv(ConvLearner):\n",
    "        @classmethod\n",
    "        def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n",
    "                   pretrained=True, **kwargs):\n",
    "            models = ResNextConvBuilder(f, data.c, data.is_multi, data.is_reg,\n",
    "            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n",
    "            return cls(data, models, precompute, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n",
    "                  dropout_p=0.5, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnext50_model(md):\n",
    "    learn = ResNextConv.pretrained(se_resnext50_32x4d, md, ps=0.5) #dropout 50%\n",
    "    learn.opt_fn = optim.Adam\n",
    "    learn.crit = FocalLoss()\n",
    "    learn.metrics = [acc]\n",
    "    learn.clip = 0.25\n",
    "    return learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test & Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "sz = 512\n",
    "nw = 6\n",
    "md = get_data(sz,bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    }
   ],
   "source": [
    "# learn = get_resnext50_model(md)\n",
    "# learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbed358000b46ca8d3f566f0a12fbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2233/3495 [18:53<10:40,  1.97it/s, loss=6.53]"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEOCAYAAACXX1DeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd8lfXd//HXJwkJZJKQwQqEPVRmwFUVFGnrHm3Vjlurd/21vbWO2trd3l3aqrV22NaiVTtV9HaAe6AoCoSNbNlDkkCADDLP9/fHOYQAyUkgJ+c64/18PPLIOde5zjnvXITzzrW+lznnEBERaUuC1wFERCSyqShERCQoFYWIiASlohARkaBUFCIiEpSKQkREglJRiIhIUCoKEREJSkUhIiJBqShERCSoJK8DdERubq4rKiryOoaISFRZtGhRuXMur7OvExVFUVRURElJidcxRESiipltCcXraNOTiIgEpaIQEZGgVBQiIhKUikJERIJSUYiISFAqChERCSqmi6KusYkNpZVexxARiWoxXRQ/fWEV037zDjPmbvQ6iohI1Irpopi7vhyAn89ezaqdBzxOIyISnWK6KLburWm+fe3fFniYREQkesV0Ufz2qnHNt8sq69i1/6CHaUREolNMF8Vl4/ux+Ifnc+7IfAB+/fJajxOJiESfmC4KgJy0ZGb8VzEAy7fv8ziNiEj0ifmiAEhIMJISjI/Kqpn2m7eZs7bU60giIlEjLooC4P7A/ooNpVX892MaslxEpKPipig+fXLv5ts9U7tRU9/Izn3auS0i0h5zznmdoV3FxcUuFBcuavI5ZszdyF0vrWmedtu04QzslcrQ/HQKMruTl5HS6fcREYkEZrbIOVfc2deJiivchUpigvGJYbnw0uFp97++7oh5fnjRaM4ZnsfQ/PQwpxMRiUxxVRQAI3tnNt++eGxfXli284jHfzZrFT8L3L7glN784ZoJJCRYGBOKiESWuNr0dMj+gw2kJifSLTGBbXtrWF9aSXJiIl98eP4x8/7y8lMo2byXH1w0mpy05JBlEBHpaqHa9BSXRdGW2oYmtlfU8Mbq0iP2YxzylbMGcfN5w9i6p4aT+2V1eR4Rkc5QUYTBGXe9wc79tUdMy89IobSyjpduOYtRfTLbeKaIiPdCVRRxc3jsifjnV07jtmnD+cPnx5Ob7j8aqrSyDoD3NpR7GU1EJGy0RnEcbn9iKXPWlZGanMj2isPnYJzUN5Pbpg3n4wO1XD2pkKRE9a+IeE+bnjz0+qrd3DFzGftqGo557BNDc7lqUiH1jT7qGn1cM7kQMx01JSLhp6LwmH/H90GufWQBOwJneE8Y0JPFW48deDA/I4UXbzmrefOViEg4qCgiiHOORp/jYEMTY37yaqvzTBtVwIxrO/3vJSLSYTozO4KYGd0SjW6JCaz66SfxOUhPSWJPVR2PvLeJP771Ea+v3s32ihr6Z6d6HVdE5Lhor2uIpSYnkZ7i799e6Sl865MjmfnV0wH45pPLiIY1OBGRllQUYVBclENRr1Tmb9rLoO++yL8XbPU6kohIh2kfRZhsKq9m6r1zmu9PKsrmojF92X2glhG9MxjVJ5MheekYMHdDOYkWGMBQROQEaWd2FGryOR6bt5mfzlrV5jzjB/RkSeDIqTl3TKEoNy1c8UQkxkT8mdlm9oiZlZrZyhbTcszsNTNbH/ie3VXvH4kSE4yLx/Zl4sBsfnrpSSQnHbv4l7Q4vHbKvXN4bumOcEYUETlGl61RmNnZQBXwuHPu5MC0XwN7nXN3m9l3gGzn3J3tvVasrFEEU9vQxBdmzGfRlgp+e9U4tu2t4b7X/NfKGJafzpC8dC4Y04eLx/TRCXwi0iFRsenJzIqAWS2KYi0wxTm3y8z6AHOccyPae514KIpDfD7XfP2LZ5fs4NYnlh4zz1t3TGGQNkmJSDsiftNTGwqcc7sAAt/zw/z+Ea/lRZIuHtuX688cdMw8U++dQ32jL5yxRCSORezhsWZ2o5mVmFlJWVmZ13E8kZhg/Oji0Wy++8Lmr8lFOQDMeHejx+lEJF6Euyh2BzY5Efhe2taMzrmHnHPFzrnivLy8sAWMdP/6yqkA/PrltSzffuy4UiIioRbuongeuDZw+1rguTC/f9RLSkzgns+MAeDns1czZ20p63dXepxKRGJZl431ZGb/BqYAuWa2HfgxcDfwpJndAGwFPttV7x/LPltcSMnmCp4o2caCTXsB+Ob5w7n5vGEeJxORWNRlReGcu6aNh87rqveMJzedO5QnSrY137/vtXXkZ6Zw1aQBHqYSkVik0WOjVGFOKpvuugCAzXtqmHrvHO58egUn9c1idJ/MI46eEhHpjIg96knaZ2aYGYNy05p3cl/0+3cZ/L0XeXPNbo/TiUisUFHEiDOG5HL28MNHh13/aAlF35nNjn0H8fkifzwvEYlcKooY8tiXJ/HHz0/gd9eMb5525t1v8u2nl3uYSkSinYoihpgZF47pwyVj+1Lyg2mM6pMJwMxF23ljtTZFiciJUVHEqNz0FF646Uzmf89/kNkNj5VwsL7J41QiEo1UFDEsKTGBgszu3HzuUADueWWtx4lEJBqpKOLAN6ePYFxhT/7xwRYqquu9jiMiUUZFESd+fPFo6pt8vLTyY6+jiEiUUVHEiXGFPRmSl8b3n13BhlKNDSUiHaeiiBNmxrTRBTgH037zDit37Pc6kohECRVFHPmfqUObb3/50YU0NuniRyLSPhVFHMns3o3Nd1/ILecNo6yyji8/upCuvBSuiMQGFUUc+kZgOPK568tbvSa3iEhLKoo4lJhgLPvRdACeW7qTbXtrPE4kIpFMRRGnslK78dj1kwGdiCciwako4tg5w/O4+dyhPL9sJ4u3VngdR0QilIoizn31nCEAXPHgPO3YFpFWqSjiXFpKEkW9UgH4cOcBj9OISCRSUQj/9/UzSU5MYOai7V5HEZEIpKIQstOSmX5SAY/O28ydM5dT36gT8UTkMBWFAHDVpEIAnijZxvAfvKQLHYlIMxWFAHDWsDx+dNFoxhX2BODx97ewbnclb60p9TiZiHjNouFIl+LiYldSUuJ1jLjxi9mr+OvcTUdMe/Z/zmwuERGJDma2yDlX3NnX0RqFHOPqyQOOmXb9ows9SCIikSDJ6wASeYbkpbPprguoa/SRkpTA7U8u4/+W7ODNNbs5d2SB1/FEJMy0RiGtMjO6d0vEzPjVlWPI7J7Ev+Zv8zqWiHhARSHtSk5K4AunDeSttaXsPlDrdRwRCTMVhXTIVcWFNPkcT5VorUIk3qgopEOKctM4bXAOzyze4XUUEQkzFYV02FnD8thYXs2m8mqvo4hIGKkopMPOH+0/4mnqvXO8DSIiYeVJUZjZbWb2oZmtNLN/m1l3L3LI8RlekNF8+6OyKg+TiEg4hb0ozKwf8A2g2Dl3MpAIXB3uHHJi3v/uuQAaC0okjni16SkJ6GFmSUAqsNOjHHKc+mT1YERBBr98cQ2llTpUViQehL0onHM7gHuBrcAuYL9z7tVw55ATd9O5QwG46i8feJxERMLBi01P2cClwCCgL5BmZl9sZb4bzazEzErKysrCHVOCuHhsX8b2z2JTeTWvfPix13FEpIt5selpGrDJOVfmnGsAngHOOHom59xDzrli51xxXl5e2ENKcI9ffyoAf3tvUztziki086IotgKnmVmqmRlwHrDagxzSCVmp3bjzUyP5YONeSjbv9TqOiHQhL/ZRzAdmAouBFYEMD4U7h3TeJeP6AvDMEp2tLRLLPDnqyTn3Y+fcSOfcyc65Lznn6rzIIZ3Tr2cPPn/qAP69YCurdx3wOo6IdBGdmS2dcvO5Q3EOPv3AXCprG7yOIyJdQEUhndInqwdXjO8HwHsbyj1OIyJdQUUhnXb3lWNITkrgt6+vp7HJ53UcEQkxFYV0WnJSAv8zZShrPq7k7x9s8TqOiISYikJC4pZpwxjZO4PZy3d5HUVEQkxFISFzwSl9KNlSwdJt+7yOIiIhpKKQkLnglN4AfOupZR4nEZFQUlFIyAzNz+Ds4Xlsq6ihyee8jiMiIaKikJC6aEwfaht8bNmjy6WKxAoVhYTU6D6ZAKzeVelxEhEJFRWFhNTQ/HR6dEvkrbWlXkcRkRBRUUhIde+WyCVj+/LSil006OQ7kZigopCQO2t4LtX1Tazcsd/rKCISAioKCbnTBvcC4P2NezxOIiKhoKKQkMtNT2FYfjpvr9UlbEVigYpCusTUkfnM37SXAxp6XCTqqSikS5w+xL/56cMduqCRSLTrUFGY2S1mlml+D5vZYjOb3tXhJHqd0i8LgBU7NO6TSLTr6BrF9c65A8B0IA/4MnB3l6WSqJebnsLgvDTeXqf9FCLRrqNFYYHvFwB/c84tazFNpFWfPrk373+0h+0VNV5HEZFO6GhRLDKzV/EXxStmlgHobCoJ6prJA0hJSuT+19Z7HUVEOiGpg/PdAIwDNjrnaswsB//mJ5E29c9O5YJT+vD66t00NvlIStSxEyLRqKP/c08H1jrn9pnZF4EfADrtVtp1/uh89h9soGRLhddRROQEdbQo/gTUmNlY4NvAFuDxLkslMePMobkkJhjzNpR7HUVETlBHi6LROeeAS4EHnHMPABldF0tiRUb3bpzSL4t5H2k4D5Fo1dGiqDSz7wJfAmabWSLQretiSSw5fUgvlm7bR3Vdo9dRROQEdLQorgLq8J9P8THQD7iny1JJTDljSC8afU77KUSOwyPvbuLhdzd5HQPoYFEEyuGfQJaZXQTUOue0j0I6pHhgDt0SjXkfaT+FSEf9dNYqfjZrFWs+9n4YnI4O4fE5YAHwWeBzwHwz+0xXBpPY0SM5kfGF2Xyg/RQix21gTprXETp8HsX3gUnOuVIAM8sDXgdmdlUwiS0TBmbz8LsbqW1oonu3RK/jiES83pnd+cSwXHoke///paP7KBIOlUTAnuN4rgjjCrNoaHKs2uX9arRINKiuaySje0f/lu9aHf2wf9nMXjGz68zsOmA28OKJvqmZ9TSzmWa2xsxWm9npJ/paEh0mDMwGoGTzXo+TiEQ+5xzV9Y2kp0RRUTjnvgU8BIwBxgIPOefu7MT7PgC87JwbGXi91Z14LYkC+RndGZybxoJNKgqR9hxsaMLnIC1CiqLDKZxzTwNPd/YNzSwTOBu4LvC69UB9Z19XIt/kQTm8uGIXPp8jIUGDD4u0parWf85RpBRF0DUKM6s0swOtfFWa2YlubB4MlAF/M7MlZjbDzLzfrS9dbvKgHA7UNrJ2d6XXUUQiWlXg5NT0FO93ZEM7ReGcy3DOZbbyleGcyzzB90wCJgB/cs6NB6qB7xw9k5ndaGYlZlZSVqaL38SCyYNyALT5SaQd1XVNAKQlR8EaRRfZDmx3zs0P3J+JvziO4Jx7yDlX7JwrzsvLC2tA6Rr9s1Pp17OHikKkHYfXKOK0KAJneW8zsxGBSecBq8KdQ7wxeVAO8zftxT/GpIi05tC4aFGxj6IL3Qz808yW478g0i89yiFhNnlQDuVVdXxUVu11FJGIVV2vosA5tzSwWWmMc+4y55xGi4sTZw3LJcHghWU7vY4iErHiftOTxLf+2amM6J3Jkm37vI4iErE2l1fTLdHomRoZV3NQUUjYndIvk+Xb9+HzaT+FSGt27q+lMDs1YsZFU1FI2BUX5bCvpoENZVVeRxGJSOWVdfRKT/Y6RjMVhYTd5CKdTyESTHlVHbnpKV7HaKaikLAb2CuVvIwUFmqAQJFWlVfVqygkvpkZk4tyWKg1CpFj1Df62H+wQUUhMqkom537a9leUeN1FJGIsrfaP0Zqbob2UUicmxQY90mbn0SO9MTCbQBaoxAZ2TuTjJQkFmzSuZYih1TXNXL/6+sAGJQbOYNqqyjEE4kJxsSibK1RiLTwzJIdAFw9qZDhBRkepzlMRSGemVSUw4bSquZtsiLxbmPg3KLvXTjK4yRHUlGIZyZrP4XIEbbtrWFEQQaZ3SNj6I5DVBTimTH9s0hOStBhsiJAXWMTr68ujcgrQKooxDMpSYmM699TaxQiwNY9/kPFzxzay+Mkx1JRiKcmDcpm5c4DzRdqEYlX2wLnFN1+/oh25gw/FYV4alJRDk0+x5KtGnZc4tuhNYoBOakeJzmWikI8NXFgNgkGC7T5SeLctoqD9OiWSG4EjRp7iIpCPJXRvRuj+mRqh7bEva17axiQk4qZeR3lGCoK8dykohyWbKugvtHndRQRz2zbW0NhBG52AhWFRIDiomxqG3ysi8DDAkXCwTnXvEYRiVQU4rkx/XoCsHz7fo+TiHhj854aauqbKMzp4XWUVqkoxHOFOT3omdqN5dt15JPEp6n3zgGgMFtrFCKtMjPG9u+pQ2QlLjU2Hd43N35ATw+TtE1FIRFhwoBs1pVWcqC2wesoImH1zaeWAXBVcSG9IugaFC2pKCQiTBjYE+dg2TatVUh8eW7pTgBG9omcYcWPpqKQiDCusCdmsHiLikLiS0Gmfy3i8vH9PE7SNhWFRISM7t0Ynp/Bkm264p3Ej8raBsoq67hp6lB6pkbeGdmHqCgkYowf4N+h7fM5r6OIhEVZZR0+B4PzIueyp61RUUjEmDAgm/0HG9hYXu11FJGweKJkGwDZaZG7NgEqCokgEwb6Dw1cvFWbnyQ+zF6+C4Bx/SPzsNhDVBQSMQbnppPZPYmlOvJJ4kBjk4+K6nr+6/SBWqMQ6aiEBGN030w+3HnA6ygiXW7Fjv1U1zcxcWC211Ha5VlRmFmimS0xs1leZZDIc1LfLNbsOkBDk0aSldh2+YPzADhjSK7HSdrn5RrFLcBqD99fItDEgdnUNfpYuUMDBErs2ldT33w7LyMyz8ZuyZOiMLP+wIXADC/eXyLXpKIcAN7fuMfjJCJd52/vbQbgma+f4W2QDvJqjeK3wLcBbV+QI+RlpDCydwbzNqgoJHa9s76MwblpTBgQ+fsnwIOiMLOLgFLn3KJ25rvRzErMrKSsrCxM6SQSTB6Uw+KtFUeMqikSK/YfbGDJ1n2M6pvpdZQO82KN4kzgEjPbDPwHONfM/nH0TM65h5xzxc654ry8vHBnFA9NHpRDTX2Tjn6SmPT5v34A+K9qFy3CXhTOue865/o754qAq4E3nXNfDHcOiVynDuoFwLsbyj1OIhJaB1v8AXTPZ8Z6nKbjdB6FRJy8jBSKeqWyQpdGlRhzaNDLu644hbSUJI/TdJynSZ1zc4A5XmaQyHRSvyyW6op3EmMODdnxqZN6e5zk+GiNQiLShAHZ7Nh3kJ37DnodRSQkauobeXtdGYkJFvFDdhxNRSER6dRB/vMp5m/SYbISG865Zw7bKw7yxVMHeB3luKkoJCKN6pNJdmq35stEikSzhiYfZZV1AFwxob/HaY6fikIiUmKCcem4fszbsIfqukav44h0yvYK/ybUn1w8mrGFkT2keGtUFBKxpp9UQH2Tj7nrdZisRLdfzPYPa3dKhF93oi0qColYk4pyyOiexJtrdnsdReSE1TU28fpq/+/wiN4ZHqc5MSoKiVjdEhM4Z3geb64p03W0JWq9taYUgILMFNKj6NyJllQUEtHOG5VPeVUdyzXsuESp11b5i+IfN5zqcZITp6KQiDZleD4JBq+t+tjrKCLH7eWVu3h68XYAhhVE52YnUFFIhMtOS+a0wb14aYWKQqLPzEU7ALh12jCPk3SOikIi3vmjC9hYXs2m8mqvo4gcl03lVUwdkcet04Z7HaVTVBQS8aaOyAfg6UXbPU4i0nGvrdrNR2XVjCuMjosTBaOikIhXlJvGGUN68eLKXVE1hr/EL5/P8ZXHSwAYVpDucZrOU1FIVPj0KX3YWFbN+tIqr6OItOvFlbuab58/usDDJKGhopCo8MnRBZjByyu1U1si29vryrjpX0sAWPGT6XRLjP6P2ej/CSQu5Gd2Z+KAbF5SUUiEu/aRBQCc1DeTjO7dPE4TGioKiRqfOrk3q3cdYLOOfpIItXTb4Yttzf7GWR4mCS0VhUSNC8f0ISnBePz9LV5HETnGhb+by2V/fA+A128/x+M0oaWikKjRJ6sHF4/ty+Pvb2ZPVZ3XcUSa7amq48OdBwDISEliaH70H+nUkopCosqNZw+m0ed4TGsVEiGWbK3g0w/MBeCKCf1Y8qPzPU4UeioKiSqj+mRy1rBcnly4jSpd0Eg8Nmv5Ti5/cB6lgavX/erKMSTFwFFOR4u9n0hi3i3nDePjA7U8+t4mr6NIHGvyOe54ahkARb1SWfzD82PiUNjWxOZPJTGtuCiHM4b0Ysa7m6ip11qFeOP6RxdS2+Dj/qvGMudbU8lJS/Y6UpdRUUhUunXacPbVNHDPK2u9jiJx6IVlO3l7XRkA54/u7XGarqeikKg0qSibATmpvLBsJ3WNTV7HkThxoLaBDzbu4eZ/+8+8nvedc6P2qnXHQ0UhUcnM+NllJ1NeVc+j7232Oo7EgW/PXMaYn7zK1Q99AMA5w/Po27OHx6nCQ0UhUevsYbkUD8zmrpfWsHz7vvafIHICnHPs3HeQJ0v8w9yP7J3B8IJ0fnXlGI+ThY+KQqKWmfHdC0YBcOWf5vH+R3s8TiSx6P7X13PG3W8C8MvLT+HlW8/m1dvOoXdWd4+ThY+KQqLaxIHZ/P2GyTQ0Ob748HzeXLPb60gSA5xz7D/YwMod+/ndG+sBuGnqUK6ZXOhxMm9YNFwIpri42JWUlHgdQyLYoi17ufJP7wNw87lD+eb0ER4nkmj1UVkV59339hHTnv7aGUwcGH1XqjOzRc654s6+jtYoJCZMHJjDn784EYDfv7mBHz67kvpGn8epJNId/Yfy+x/tOaYkpo8uiMqSCCWtUUhM8fkcd8xcxjOLdwDw/E1nMqZ/T49TSaRpaPJxzytr+dt7m2hocgzslcq3PjmC55bu5LVVuxmcm8Yb3zwHM/M6aqeEao0i7EVhZoXA40BvwAc85Jx7INhzVBRyPGobmpgxdyP3vrqOwpweZKcmc3K/LMb0y6IgqztTR+R7HVE8sr2ihhsfX8SqXQfanOesYbn8/YZTw5iq60RzUfQB+jjnFptZBrAIuMw5t6qt56go5ER8sHFP8zHvLf3i8pO5etIAEhOi+69FOT7bK2r47J/fZ9f+2uZpL9z0CU7qm8m7G8q58+nl7Npfy9xvT6UwJ9XDpKETtUVxTACz54A/OOdea2seFYWcqDlrS3l11W721zRQWlnLws0VzY/lpCXz8i1nkZ8ZP4c5xpv9Bxt4b0M5g3LTuOLBeRxsaOKayYXcMX0E2anJJMT4HwsxURRmVgS8A5zsnDtw1GM3AjcCDBgwYOKWLbr+gHRefaOPn81axd8/OPz79LUpQ7j9/OExO/JnvFqytYLLH5x3xLRJRdnMuHYSWT1i41rW7Yn6ojCzdOBt4BfOuWeCzas1Cgm1tR9X8uHO/dz+pH+Y6MQEY953zqUgsHbhnIv6HZnxqqqukc3l1Tzy3iaeWbyDwblp1DX6mH5SAT+4cHRcbXKM6qIws27ALOAV59xv2ptfRSFdpb7Rx+1PLmXW8l1tznPJ2L6cNyqfS8b2jbvycM7x3NKdnD08L+KH0d61/yBrdlXy5UcXNk+bODCbp792hoepvBW1RWH+/2mPAXudc7d25DkqCulqi7dWcPVDH1Df6CMpwWj0tf7/4tRBOXxUVkV5VT1FvVJ5+dazSTAjOSl0m62afI4Eo7mUXlyxi6//czHjCnty8di+XHv6wKBXUZsxdyOzV+xiZO8Mxg/Ipn92DzaX1zB1ZB556SnHPHdvdT3Zqd3423ubGVuYxZY9Nfgc/Pb1dWyvONg834NfmMD00QUkJSbgnGPHvoOs3LGfiQNzyMtIaV4La29tzOdzLNlWwfjCbKzFz3ki3li9mxsea/uz4ZHrijl3ZMEJv360i+ai+AQwF1iB//BYgO85515s6zkqCgmnQx90DU0+DNhTXc8t/1nCBxv3tvmcB64ex5Th+WSlHt+279IDtXxr5nLG9s/iuWU7yeiexMod/t116SlJbV7u9YoJ/bhj+ggqauoZlp/But2VvLO+jIfnbmJPdX2b7zc0P50bzx7M1BH55GWk8Ps31nPfa+uOK3NHnTooh3NH5jOusCeTB+XgHCzdvo97X1nLvMC4XL3Skvn+haO4fHy/DhfGC8t28vPZq6ipb6Ky9vDyGdgrlSnD81hfWsVD/1UcF8N/tydqi+JEqCgkUuyvaSAtJZGkxAQem7eZR97bxJY9NUfMk5qcyHVnFPGpk3szpn9PSjbvZeWO/azdXUltg4+vnDWYDWVV3P/aOjaVV7f5XnkZKZQFrsU862b/YZx/nbuRX764JmjG5MQEvnDaAEoP1DF7hX+T2qXj+lJeVcd7G4IPnGgG3ZMSGZKfxlfPGcKaXZV86fSBLN5SwTf+s4SGpsOfF4kJRpPPkZ+Rgs85yqvqyeiedMSHd3OmpISgZ8pPHJjNp07qzfSTCliwaS93Pr2cYfkZTD+pgNW7KimvquPUQTm8va6MNR9XAv7Lj+6trmfaqAK+f+EoeqWnBP3Z4pGKQiRC7Np/kAdeX89/Fm47oeffNm04l43vS9+ePdhTVU9mjyS6JSbQLbCJB47cPFN6oJb/W7KDu15aw+RBOQzISaW+0Ud9o4+vTx0S9Ez0/QcbePS9zdz/+uG1iPs+O5ZzRuSRlpxEj+TEoFl9Pv8mp95Z3UlKsDbXAnw+xx/e2sDirRU0+RxllXWs+biS1ORE7rriFC4d1w+AxiYfX3p4Ae9v7PjIv+MKe3Lf58YyJC+9w8+JVyoKkQhV19hEyeYK/vjWBuZ9tIcLx/ShvLIusHkF5m/cS1ZqN84alhvX288PqW1o4qmSbTT5HDMXb6eoVxp3fmok/bN7sHTbPsyM9JQk1nx8gKJeaZzcL8vryFFDRSEiIkFp9FgREQkLFYWIiASlohARkaBUFCIiEpSKQkREglJRiIhIUCoKEREJSkUhIiJBRcUJd2ZWBuwD9h/1UNZR046+nwuUd2G0o98v1M9rb762Hm9tekemafm1PV3Lr+OPa/l1bL5wLL8051xeB7IG55yLii/gofamtXK/JNyZQvm89uZr6/GOLCstPy0/LT8tv466CEfXAAAII0lEQVR+RdOmpxc6MK21ebrSib5fR5/X3nxtPd6RZdXaNC2/tqdr+XX8cS2/js0XNcsvKjY9nSgzK3EhGOckXmn5dY6WX+do+XVOKJdfNK1RnIiHvA4Q5bT8OkfLr3O0/DonZMsvptcoRESk82J9jUJERDpJRSEiIkGpKEREJKi4LAozm2Jmc83sz2Y2xes80cjM0sxskZld5HWWaGNmowK/ezPN7Gte54k2ZnaZmf3VzJ4zs+le54k2ZjbYzB42s5kdfU7UFYWZPWJmpWa28qjpnzKztWa2wcy+087LOKAK6A5s76qskShEyw/gTuDJrkkZuUKx/Jxzq51zXwU+B8TV4Z8hWn7POue+AlwHXNWFcSNOiJbfRufcDcf1vtF21JOZnY3/Q/5x59zJgWmJwDrgfPwf/AuBa4BE4K6jXuJ6oNw55zOzAuA3zrkvhCu/10K0/MbgHx6gO/5lOSs86b0XiuXnnCs1s0uA7wB/cM79K1z5vRaq5Rd43n3AP51zi8MU33MhXn4znXOf6cj7JoUmfvg4594xs6KjJk8GNjjnNgKY2X+AS51zdwHBNo1UACldkTNShWL5mdlUIA0YDRw0sxedc74uDR4hQvX755x7HnjezGYDcVMUIfr9M+Bu4KV4KgkI+edfh0VdUbShH7Ctxf3twKltzWxmVwCfBHoCf+jaaFHhuJafc+77AGZ2HYG1sy5NF/mO9/dvCnAF/j9SXuzSZNHhuJYfcDMwDcgys6HOuT93ZbgocLy/f72AXwDjzey7gUIJKlaKwlqZ1uY2NefcM8AzXRcn6hzX8muewblHQx8lKh3v798cYE5XhYlCx7v8fgf8ruviRJ3jXX57gK8ezxtE3c7sNmwHClvc7w/s9ChLNNLy6xwtv87R8uucLl9+sVIUC4FhZjbIzJKBq4HnPc4UTbT8OkfLr3O0/Dqny5df1BWFmf0beB8YYWbbzewG51wjcBPwCrAaeNI596GXOSOVll/naPl1jpZf53i1/KLu8FgREQmvqFujEBGR8FJRiIhIUCoKEREJSkUhIiJBqShERCQoFYWIiASlopCQM7OqMLzHJR0cDj2U7znFzM44geeNN7MZgdvXmVlEjC9mZkVHD1fdyjx5ZvZyuDJJZFJRSMQKDJ/cKufc8865u7vgPYONfzYFOO6iAL4H/P6EAnnMOVcG7DKzM73OIt5RUUiXMrNvmdlCM1tuZv/bYvqz5r9C3odmdmOL6VVm9lMzmw+cbmabzex/zWyxma0ws5GB+Zr/MjezR83sd2Y2z8w2mtlnAtMTzOzBwHvMMrMXDz12VMY5ZvZLM3sbuMXMLjaz+Wa2xMxeN7OCwNDOXwVuM7OlZnZW4K/tpwM/38LWPkzNLAMY45xb1spjA83sjcCyecPMBgSmDzGzDwKv+dPW1tDMf4XB2Wa2zMxWmtlVgemTAsthmZktMLOMwJrD3MAyXNzaWpGZJZrZPS3+rf5fi4efBeLmmi3SCuecvvQV0i+gKvB9OvAQ/tEtE4BZwNmBx3IC33sAK4FegfsO+FyL19oM3By4/XVgRuD2dfgv+gPwKPBU4D1G4x+bH+Az+IfxTgB647/+yGdayTsHeLDF/WwOj1rw38B9gds/Ae5oMd+/gE8Ebg8AVrfy2lOBp1vcb5n7BeDawO3rgWcDt2cB1wRuf/XQ8jzqda8E/trifhaQDGwEJgWmZeIfIToV6B6YNgwoCdwuAlYGbt8I/CBwOwUoAQYF7vcDVnj9e6Uv775iZZhxiUzTA19LAvfT8X9QvQN8w8wuD0wvDEzfAzQBTx/1OoeGhF+E/zoOrXnW+a+Lscr8Vy4E+ATwVGD6x2b2VpCsT7S43R94wsz64P/w3dTGc6YBo82aR3nONLMM51xli3n6AGVtPP/0Fj/P34Fft5h+WeD2v4B7W3nuCuBeM/sVMMs5N9fMTgF2OecWAjjnDoB/7QP4g5mNw798h7fyetOBMS3WuLLw/5tsAkqBvm38DBIHVBTSlQy4yzn3lyMm+i/cMw043TlXY2Zz8F9WFaDWOdd01OvUBb430fbvbF2L23bU946obnH79/gvkft8IOtP2nhOAv6f4WCQ1z3I4Z+tPR0eeM05t87MJgIXAHeZ2av4NxG19hq3AbuBsYHMta3MY/jX3F5p5bHu+H8OiVPaRyFd6RXgejNLBzCzfmaWj/+v1YpASYwETuui938XuDKwr6IA/87ojsgCdgRuX9tieiWQ0eL+q/hH7QQg8Bf70VYDQ9t4n3n4h4QG/z6AdwO3P8C/aYkWjx/BzPoCNc65f+Bf45gArAH6mtmkwDwZgZ3zWfjXNHzAl/BfS/lorwBfM7NugecOD6yJgH8NJOjRURLbVBTSZZxzr+LfdPK+ma0AZuL/oH0ZSDKz5cDP8H8wdoWn8V/UZSXwF2A+sL8Dz/sJ8JSZzQXKW0x/Abj80M5s4BtAcWDn7ypauWqYc24N/kt2Zhz9WOD5Xw4shy8BtwSm3wrcbmYL8G+6ai3zKcACM1sKfB/4uXOuHrgK+L2ZLQNew7828CBwrZl9gP9Dv7qV15sBrAIWBw6Z/QuH196mArNbeY7ECQ0zLjHNzNKdc1Xmv07wAuBM59zHYc5wG1DpnJvRwflTgYPOOWdmV+PfsX1pl4YMnucd4FLnXIVXGcRb2kchsW6WmfXEv1P6Z+EuiYA/AZ89jvkn4t/5bMA+/EdEecLM8vDvr1FJxDGtUYiISFDaRyEiIkGpKEREJCgVhYiIBKWiEBGRoFQUIiISlIpCRESC+v/pLbYpkg+vCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learn.lr_find()\n",
    "# learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875746120beb464886244eebad8aff49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 82/3495 [01:02<43:26,  1.31it/s, loss=30]    "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x864 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learn.lr_find2()\n",
    "# learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "lrs=np.array([lr/10,lr/3,lr])\n",
    "model_id = 'SEResNext50_Mk1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d63decf64c64b698b87470e752db8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                          \n",
      "    0      1.384055   1.184798   0.948302  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1847979014444536, 0.9483016196211639]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59130dcbdb445da8aeb8a6ff02abe1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                          \n",
      "    0      1.078669   0.966236   0.956725  \n",
      "    1      1.059594   0.892402   0.959046                      \n",
      "    2      0.935106   0.794946   0.962999                      \n",
      "    3      0.911128   0.754595   0.965102                      \n",
      "    4      0.828862   0.714963   0.966159                      \n",
      "    5      0.769191   0.692742   0.967204                      \n",
      "CPU times: user 6h 34min 25s, sys: 4h 23min 10s, total: 10h 57min 35s\n",
      "Wall time: 2h 46min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "phase = 1\n",
    "learn.unfreeze()\n",
    "learn.fit(lrs/3,3,cycle_len=2,\n",
    "          use_clr=(10,20), \n",
    "          best_save_name=f'{model_id}_{phase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622e0f4eb090477badfa6d88516986c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.803923   0.678944   0.96802   \n",
      "    1      0.783068   0.659938   0.968687                      \n",
      "    2      0.751022   0.641457   0.969767                      \n",
      "    3      0.719631   0.642843   0.969411                      \n",
      "    4      0.768724   0.625307   0.970169                      \n",
      "    5      0.720313   0.616126   0.970514                      \n",
      "    6      0.683994   0.611221   0.970939                      \n",
      "    7      0.677048   0.600325   0.971617                      \n",
      "    8      0.664782   0.594959   0.971835                      \n",
      "    9      0.638504   0.592827   0.972077                      \n",
      "    10     0.647609   0.58502    0.972284                      \n",
      "    11     0.696528   0.587539   0.972134                      \n",
      "    12     0.654107   0.582401   0.972456                      \n",
      "    13     0.667853   0.577229   0.972847                      \n",
      "    14     0.597091   0.572194   0.973088                      \n",
      "    15     0.629614   0.572426   0.972939                      \n",
      "    16     0.621325   0.568628   0.97303                       \n",
      "    17     0.598749   0.564727   0.973651                      \n",
      "    18     0.614315   0.56707    0.97341                       \n",
      "    19     0.581521   0.569853   0.972812                      \n",
      "    20     0.612328   0.560336   0.973651                      \n",
      "    21     0.623136   0.569722   0.973375                      \n",
      "    22     0.580681   0.565911   0.973329                      \n",
      "    23     0.626172   0.568695   0.97349                       \n",
      "    24     0.595337   0.562178   0.973421                      \n",
      "    25     0.582808   0.566312   0.973329                      \n",
      "    26     0.583887   0.559393   0.974134                      \n",
      "    27     0.564763   0.554936   0.973754                      \n",
      "    28     0.553906   0.567135   0.97318                       \n",
      "    29     0.530175   0.55891    0.9738                        \n",
      "    30     0.590292   0.56298    0.974122                      \n",
      "    31     0.560593   0.553654   0.974226                      \n",
      "    32     0.543306   0.558349   0.974157                      \n",
      "    33     0.519412   0.56196    0.974065                      \n",
      "    34     0.513873   0.558538   0.973938                      \n",
      "    35     0.525148   0.568876   0.973697                      \n",
      "    36     0.500936   0.557138   0.974271                      \n",
      "    37     0.513994   0.551314   0.974501                      \n",
      "    38     0.514559   0.556947   0.974547                      \n",
      "    39     0.479037   0.562603   0.973777                      \n",
      "    40     0.485516   0.563521   0.973731                      \n",
      "    41     0.485141   0.564062   0.974271                      \n",
      "    42     0.489808   0.557644   0.974375                      \n",
      "    43     0.496916   0.565681   0.973536                      \n",
      "    44     0.449701   0.560623   0.973835                      \n",
      "    45     0.46431    0.573054   0.974582                      \n",
      "CPU times: user 2d 2h 6min 9s, sys: 1d 9h 9min 56s, total: 3d 11h 16min 5s\n",
      "Wall time: 21h 30min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "phase = 2\n",
    "learn.fit(lrs/5,2,cycle_len=23,\n",
    "          use_clr=(10,20),\n",
    "          best_save_name=f'{model_id}_{phase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7502511f2844beb25e2b1b032172e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.468346   0.562558   0.974203  \n",
      "    1      0.431962   0.557532   0.974478                      \n",
      "    2      0.449179   0.566225   0.97457                       \n",
      "    3      0.445568   0.566574   0.973984                      \n",
      "    4      0.445385   0.568733   0.974271                      \n",
      "    5      0.449579   0.570855   0.974134                      \n",
      "    6      0.409382   0.571065   0.974157                      \n",
      "    7      0.435574   0.557584   0.974478                      \n",
      "CPU times: user 8h 47min 8s, sys: 5h 53min 29s, total: 14h 40min 38s\n",
      "Wall time: 3h 42min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "phase = 3\n",
    "learn.fit(lrs/9,1,cycle_len=8,\n",
    "          use_clr=(5,20),\n",
    "          best_save_name=f'{model_id}_{phase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48ccd3769b8440ca351ed590c5c050a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.417849   0.576096   0.974271  \n",
      "    1      0.435696   0.574954   0.974375                      \n",
      "    2      0.413814   0.568115   0.974421                      \n",
      "    3      0.438606   0.582702   0.97418                       \n",
      "    4      0.421163   0.572526   0.974421                      \n",
      "CPU times: user 5h 29min 37s, sys: 3h 40min 41s, total: 9h 10min 19s\n",
      "Wall time: 2h 18min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "phase = 4\n",
    "learn.fit(lrs/18,1,cycle_len=5,\n",
    "          use_clr=(5,20),\n",
    "          best_save_name=f'{model_id}_{phase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(f'{model_id}_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified KFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "folds = 3\n",
    "train_folds = []\n",
    "val_folds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folds():\n",
    "    skf = StratifiedKFold(n_splits=folds, random_state=1234, shuffle=True)\n",
    "    \n",
    "    train_names = list({f[:36] for f in os.listdir(TRAIN)})\n",
    "    test_names = list({f[:36] for f in os.listdir(TEST)})\n",
    "    trn_df = pd.read_csv('data/train.csv')\n",
    "    \n",
    "    for train_index, evaluate_index in skf.split(trn_df.index.values, trn_df.Target):\n",
    "        trn_value = trn_df.iloc[train_index]\n",
    "        val_value = trn_df.iloc[evaluate_index]\n",
    "        train_folds.append(trn_value)\n",
    "        val_folds.append(val_value)\n",
    "        print(train_index.shape, evaluate_index.shape)\n",
    "    \n",
    "    for i in range(folds):\n",
    "        train_folds[i].to_csv(f'trn_folds_{i}')\n",
    "        val_folds[i].to_csv(f'val_folds_{i}')\n",
    "\n",
    "def load_folds():\n",
    "    for i in range(folds):\n",
    "        train_folds.append(pd.read_csv(f'trn_folds_{i}'))\n",
    "        val_folds.append(pd.read_csv(f'val_folds_{i}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_folds()\n",
    "load_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(sz, bs, k):\n",
    "    aug_tfms = [RandomRotate(30, tfm_y=TfmType.NO),\n",
    "                RandomDihedral(tfm_y=TfmType.NO),\n",
    "                RandomLighting(0.05, 0.05, tfm_y=TfmType.NO)]\n",
    "    \n",
    "    stats = A([0.00505, 0.00331, 0.00344, 0.00519], [0.10038, 0.08131, 0.08284, 0.10179])\n",
    "    tfms = tfms_from_stats(stats, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, \n",
    "                aug_tfms=aug_tfms)\n",
    "    \n",
    "    trn_x = list(train_folds[k]['Id'])\n",
    "    val_x = list(val_folds[k]['Id'])\n",
    "    \n",
    "    ds = ImageData.get_ds(pdFilesDataset, (trn_x[:-(len(trn_x)%bs)],TRAIN), \n",
    "                (val_x,TRAIN), tfms, test=(test_names,TEST))\n",
    "    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_t = np.array([0.565,0.39,0.55,0.345,0.33,0.39,0.33,0.45,0.38,0.39,\n",
    "               0.34,0.42,0.31,0.38,0.49,0.50,0.38,0.43,0.46,0.40,\n",
    "               0.39,0.505,0.37,0.47,0.41,0.545,0.32,0.1])\n",
    "\n",
    "def make_prediction():\n",
    "    preds,y = learn.TTA(is_test=True)\n",
    "    preds = np.stack(preds, axis=-1)\n",
    "    preds = sigmoid_np(preds)\n",
    "    pred = preds.max(axis=-1)\n",
    "    return pred\n",
    "\n",
    "def save_pred(pred, th=0.5, fname='protein_classification.csv'):\n",
    "    pred_list = []\n",
    "    for line in pred:\n",
    "        s = ' '.join(list([str(i) for i in np.nonzero(line>th)[0]]))\n",
    "        pred_list.append(s)\n",
    "        \n",
    "    sample_df = pd.read_csv(SAMPLE)\n",
    "    sample_list = list(sample_df.Id)\n",
    "    pred_dic = dict((key, value) for (key, value) \n",
    "                in zip(learn.data.test_ds.fnames,pred_list))\n",
    "    pred_list_cor = [pred_dic[id] for id in sample_list]\n",
    "    df = pd.DataFrame({'Id':sample_list,'Predicted':pred_list_cor})\n",
    "    df.to_csv(fname, header=True, index=False)\n",
    "\n",
    "def sigmoid_np(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "lrs=np.array([lr/10,lr/3,lr])\n",
    "epochs=60\n",
    "wd=1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHANGE THIS BACK TO FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e91f084d5854f11a8b46f45b2685f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 190/2588 [00:57<12:02,  3.32it/s, loss=10.2]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-c7b0af6e129d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     learn.fit(lr, 1, cycle_len=3, wds=1e-7, \n\u001b[1;32m      6\u001b[0m               \u001b[0muse_wd_sched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m               use_clr_beta=(10, 10, 0.95, 0.85))\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mval_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIterBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/dataloader.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(batch, pin, half)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"batch must contain numbers, dicts or lists; found {type(batch)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"batch must contain numbers, dicts or lists; found {type(batch)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/dataloader.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(batch, pin, half)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpin\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/core.py\u001b[0m in \u001b[0;36mto_gpu\u001b[0;34m(x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m'''puts pytorch variable to gpu, if cuda is avaialble and USE_GPU is set to true. '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mUSE_GPU\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #CHANGE THIS BACK TO FOLDS!!!!!!!!!!!\n",
    "# for k in range(1,folds):\n",
    "#     print(f'Fold: {k+1}')\n",
    "#     md = get_fold(sz,bs,k)\n",
    "#     learn = get_resnext50_model(md)\n",
    "#     learn.fit(lr, 1, cycle_len=3, wds=1e-7, \n",
    "#               use_wd_sched=True, \n",
    "#               use_clr_beta=(10, 10, 0.95, 0.85))\n",
    "    \n",
    "#     learn.unfreeze()\n",
    "    \n",
    "#     phase=2\n",
    "    \n",
    "#     learn.fit(lrs, 1, cycle_len=epochs, wds=wd, \n",
    "#               use_wd_sched=True, use_clr_beta=(10, 10, 0.95, 0.85),\n",
    "#               best_save_name=f'SEResNext50_{k}_{phase}')\n",
    "    \n",
    "#     pred = make_prediction()\n",
    "#     save_pred(pred, th_t, fname=f'protein_class_{k}')\n",
    "    \n",
    "#     learn.save(f'SEResNext50_{k}_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f7c4432f0a4c459cfa4ef8af60fc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.708683   0.688416   0.968507  \n",
      "    1      0.701281   0.67175    0.968997                      \n",
      "    2      0.702024   0.670381   0.969301                      \n",
      "    3      0.723029   0.66552    0.969825                      \n",
      "    4      0.676484   0.664217   0.969301                      \n",
      "    5      0.672372   0.652564   0.969913                      \n",
      "    6      0.63114    0.651776   0.970126                      \n",
      "    7      0.660796   0.645201   0.970224                      \n",
      "    8      0.603924   0.648501   0.970065                      \n",
      "    9      0.682439   0.645595   0.970194                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95fbbc554874202a134971987c7960d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.661653   0.644687   0.970204  \n",
      "    1      0.651977   0.646255   0.96971                       \n",
      "    2      0.626746   0.641681   0.969967                      \n",
      "    3      0.626203   0.640765   0.970363                      \n",
      "    4      0.647354   0.644649   0.970001                      \n",
      "    5      0.617247   0.642343   0.97016                       \n",
      "    6      0.635979   0.641148   0.97014                       \n",
      "    7      0.651673   0.639772   0.970352                      \n",
      "    8      0.612374   0.638036   0.970288                      \n",
      "    9      0.643237   0.640806   0.970471                      \n",
      "    10     0.665701   0.64033    0.970366                      \n",
      "    11     0.63378    0.636745   0.970464                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470e5c2cbb0047d983c90b6ac281d220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.631731   0.634139   0.970275  \n",
      "    1      0.652811   0.636452   0.9704                        \n",
      "    2      0.623109   0.648265   0.97041                       \n",
      "    3      0.595712   0.64267    0.970275                      \n",
      "    4      0.648243   0.641561   0.970478                      \n",
      "    5      0.620362   0.636634   0.970363                      \n",
      "    6      0.641006   0.635967   0.970342                      \n",
      "    7      0.590809   0.635668   0.970312                      \n",
      "    8      0.64267    0.638516   0.970423                      \n",
      "    9      0.601674   0.631897   0.97043                       \n",
      "    10     0.617109   0.639105   0.970488                      \n",
      "    11     0.578321   0.637812   0.97068                       \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8916de24f93e431a8e3e5a49d7fdea51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.624135   0.64154    0.970745  \n",
      "    1      0.614767   0.635468   0.970592                      \n",
      "    2      0.601883   0.638803   0.970464                      \n",
      "    3      0.612241   0.633846   0.970724                      \n",
      "    4      0.661467   0.637457   0.970667                      \n",
      "    5      0.627133   0.635731   0.970444                      \n",
      "    6      0.653279   0.633895   0.970231                      \n",
      "    7      0.612823   0.633962   0.970592                      \n",
      "    8      0.614174   0.639119   0.970305                      \n",
      "                                                  \r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'learner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-169e6807f8b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0msave_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'protein_class_{k}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'SEResNext50_{k}_{phase}_final'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-bf9fe4c50e2c>\u001b[0m in \u001b[0;36msave_pred\u001b[0;34m(pred, th, fname)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msample_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     pred_dic = dict((key, value) for (key, value) \n\u001b[0;32m---> 21\u001b[0;31m                 in zip(learner.data.test_ds.fnames,pred_list))\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mpred_list_cor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpred_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Predicted'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpred_list_cor\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learner' is not defined"
     ]
    }
   ],
   "source": [
    "for k in range(folds):\n",
    "    print(f'Fold: {k+1}')\n",
    "    md = get_fold(sz,bs,k)\n",
    "    learn = get_resnext50_model(md)\n",
    "    learn.load(f'SEResNext50_0_2')\n",
    "\n",
    "    learn.fit(lr, 1, cycle_len=10, wds=1e-7, \n",
    "          use_wd_sched=True, \n",
    "          use_clr_beta=(10, 10, 0.95, 0.85))\n",
    "    \n",
    "    phase=1\n",
    "    learn.fit(lrs/4,4,\n",
    "              cycle_len=3,use_clr=(10,20), \n",
    "              best_save_name=f'SEResNext50_{k}_{phase}_cylic')\n",
    "    \n",
    "    phase=2\n",
    "    learn.fit(lrs/4,2,\n",
    "              cycle_len=6,use_clr=(10,20),\n",
    "              best_save_name=f'SEResNext50_{k}_{phase}_cylic')\n",
    "    \n",
    "    phase=3\n",
    "    learn.fit(lrs/16,1,\n",
    "              cycle_len=9,use_clr=(5,20),\n",
    "              best_save_name=f'SEResNext50_{k}_{phase}_cylic')\n",
    "    \n",
    "    pred = make_prediction()\n",
    "    save_pred(pred, th_t, fname=f'protein_class_{k}')\n",
    "    \n",
    "    learn.save(f'SEResNext50_{k}_{phase}_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd35eee12ff34f3b9e293b5b02d03a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.690399   0.644341   0.96982   \n",
      "    1      0.677506   0.626919   0.970795                      \n",
      "    2      0.696944   0.617971   0.971071                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fb1023ea1943e684f358091a80fc07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.695288   0.612037   0.971474  \n",
      "    1      0.655692   0.611929   0.971347                      \n",
      "    2      0.682721   0.600307   0.971798                      \n",
      "    3      0.728619   0.601302   0.971602                      \n",
      "    4      0.69491    0.596661   0.972032                      \n",
      "    5      0.647442   0.602972   0.97165                       \n",
      "    6      0.658217   0.60524    0.971278                      \n",
      "    7      0.689975   0.59892    0.971826                      \n",
      "    8      0.696156   0.595936   0.971781                      \n",
      "    9      0.691441   0.598844   0.971898                      \n",
      "    10     0.675263   0.599668   0.971881                      \n",
      "    11     0.659693   0.593455   0.972029                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904b4436b0f947ddb973411593e9e0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=18), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.690898   0.594015   0.971801  \n",
      "    1      0.688713   0.592242   0.972077                      \n",
      "    2      0.665784   0.594244   0.972056                      \n",
      "    3      0.644583   0.591885   0.971936                      \n",
      "    4      0.667377   0.591405   0.971977                      \n",
      "    5      0.664288   0.589727   0.971674                      \n",
      "    6      0.665024   0.592484   0.971788                      \n",
      "    7      0.652159   0.594615   0.971801                      \n",
      "    8      0.652922   0.59333    0.971677                      \n",
      "    9      0.663346   0.588364   0.972098                      \n",
      "    10     0.630202   0.590772   0.972032                      \n",
      "    11     0.648189   0.589787   0.972022                      \n",
      "    12     0.676139   0.591582   0.971826                      \n",
      "    13     0.648723   0.587968   0.972053                      \n",
      "    14     0.637731   0.590833   0.972239                      \n",
      "    15     0.658647   0.585616   0.972001                      \n",
      "    16     0.614379   0.588272   0.972122                      \n",
      "    17     0.658091   0.584674   0.971795                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee0848d532647fcab403aec4d4efb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.651425   0.581      0.972501  \n",
      "    1      0.680418   0.589852   0.972163                      \n",
      "    2      0.647631   0.588831   0.972187                      \n",
      "    3      0.661833   0.585191   0.971753                      \n",
      "    4      0.642752   0.583434   0.97228                       \n",
      "    5      0.655927   0.583674   0.972022                      \n",
      "    6      0.664876   0.584974   0.972139                      \n",
      "    7      0.643492   0.591691   0.971839                      \n",
      "    8      0.677545   0.585221   0.971915                      \n",
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "md = get_fold(sz,bs,k)\n",
    "learn = get_resnext50_model(md)\n",
    "learn.load(f'SEResNext50_0_2')\n",
    "\n",
    "learn.fit(lr, 1, cycle_len=3, wds=1e-7, \n",
    "      use_wd_sched=True, \n",
    "      use_clr_beta=(10, 10, 0.95, 0.85))\n",
    "\n",
    "phase=1\n",
    "learn.fit(lrs/4,4,\n",
    "          cycle_len=3,use_clr=(10,20), \n",
    "          best_save_name=f'SEResNext50_{k}_{phase}_cylic')\n",
    "\n",
    "phase=2\n",
    "learn.fit(lrs/4,2,\n",
    "          cycle_len=9,use_clr=(10,20),\n",
    "          best_save_name=f'SEResNext50_{k}_{phase}_cylic')\n",
    "\n",
    "phase=3\n",
    "learn.fit(lrs/16,1,\n",
    "          cycle_len=9,use_clr=(5,20),\n",
    "          best_save_name=f'SEResNext50_{k}_{phase}_cylic')\n",
    "\n",
    "pred = make_prediction()\n",
    "save_pred(pred, th_t, fname=f'protein_class_{k}.csv')\n",
    "\n",
    "learn.save(f'SEResNext50_{k}_{phase}_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6de8ae429e24cbc8b1a40dc1251e67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.761065   0.622297   0.970938  \n",
      "    1      0.758715   0.606254   0.971509                      \n",
      "    2      0.720551   0.603033   0.971822                      \n",
      "    3      0.723014   0.602866   0.971991                      \n",
      "    4      0.730249   0.600643   0.97141                       \n",
      "    5      0.708055   0.584863   0.972653                      \n",
      "    6      0.741488   0.584287   0.972368                      \n",
      "    7      0.688735   0.581421   0.972636                      \n",
      "    8      0.722914   0.577533   0.972601                      \n",
      "    9      0.665531   0.583123   0.972182                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b02834a09c4dbbaf14dd4776f5ffea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.704405   0.577783   0.972823  \n",
      "    1      0.701424   0.573068   0.972742                      \n",
      "    2      0.655243   0.570751   0.973132                      \n",
      "    3      0.673378   0.574082   0.972985                      \n",
      "    4      0.656189   0.58247    0.972858                      \n",
      "    5      0.676121   0.573113   0.972815                      \n",
      "    6      0.656515   0.576367   0.972911                      \n",
      "    7      0.679499   0.574191   0.973034                      \n",
      "    8      0.643987   0.569432   0.972999                      \n",
      "    9      0.62719    0.571271   0.972999                      \n",
      "    10     0.666447   0.568745   0.97302                       \n",
      "    11     0.631027   0.568487   0.97328                       \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f32987e74e4283a755aa8558cd3ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.647338   0.568972   0.972844  \n",
      "    1      0.669681   0.569243   0.97272                       \n",
      "    2      0.658452   0.57482    0.97265                       \n",
      "    3      0.635363   0.568029   0.973178                      \n",
      "    4      0.655082   0.572341   0.973161                      \n",
      "    5      0.67288    0.565687   0.973432                      \n",
      "    6      0.654757   0.570893   0.97278                       \n",
      "    7      0.659133   0.567313   0.973284                      \n",
      "    8      0.692987   0.571273   0.973055                      \n",
      "    9      0.6652     0.572821   0.972893                      \n",
      "    10     0.648255   0.574641   0.972798                      \n",
      "    11     0.655446   0.566681   0.973016                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234a2837639043d19ee446b294728144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.654666   0.568369   0.973111  \n",
      "    1      0.640458   0.567117   0.973245                      \n",
      "    2      0.659919   0.564301   0.973238                      \n",
      "    3      0.6601     0.570541   0.972981                      \n",
      "    4      0.687968   0.568847   0.972977                      \n",
      "    5      0.655544   0.57377    0.972565                      \n",
      "    6      0.632384   0.571387   0.973041                      \n",
      "    7      0.647734   0.564062   0.973259                      \n",
      "    8      0.677736   0.568093   0.973041                      \n",
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "md = get_fold(sz,bs,k)\n",
    "learn = get_resnext50_model(md)\n",
    "learn.load(f'SEResNext50_0_2')\n",
    "\n",
    "learn.fit(lr, 1, cycle_len=10, wds=1e-7, \n",
    "      use_wd_sched=True, \n",
    "      use_clr_beta=(10, 10, 0.95, 0.85))\n",
    "\n",
    "phase=1\n",
    "learn.fit(lrs/4,4,\n",
    "          cycle_len=3,use_clr=(10,20), \n",
    "          best_save_name=f'SEResNext50_{k}_{phase}_cylic')\n",
    "\n",
    "phase=2\n",
    "learn.fit(lrs/4,2,\n",
    "          cycle_len=6,use_clr=(10,20),\n",
    "          best_save_name=f'SEResNext50_{k}_{phase}_cylic')\n",
    "\n",
    "phase=3\n",
    "learn.fit(lrs/16,1,\n",
    "          cycle_len=9,use_clr=(5,20),\n",
    "          best_save_name=f'SEResNext50_{k}_{phase}_cylic')\n",
    "\n",
    "pred = make_prediction()\n",
    "save_pred(pred, th_t, fname=f'protein_class_{k}.csv')\n",
    "\n",
    "learn.save(f'SEResNext50_{k}_{phase}_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/SEResNext50_0_3_final.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-6b33746ff644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_resnext50_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'SEResNext50_{k}_3_final'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'swa_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-swa.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/torch_imports.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(m, p)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/SEResNext50_0_3_final.h5'"
     ]
    }
   ],
   "source": [
    "for k in range(folds):\n",
    "    print(f'Fold: {k}')\n",
    "    md = get_fold(sz,bs,k)\n",
    "    learn = get_resnext50_model(md)\n",
    "    learn.load(f'SEResNext50_{k}_3_final')\n",
    "    learn.unfreeze()\n",
    "    \n",
    "    phase=4\n",
    "    learn.fit(lrs,2,\n",
    "              cycle_len=9,use_clr=(10,20),\n",
    "              best_save_name=f'SEResNext50_{k}_{phase}_cylic')\n",
    "    \n",
    "    phase=5\n",
    "    learn.fit(lrs/8,2,\n",
    "              cycle_len=9,use_clr=(5,20),\n",
    "              best_save_name=f'SEResNext50_{k}_{phase}_cylic')\n",
    "    \n",
    "    pred = make_prediction()\n",
    "    save_pred(pred, th_t, fname=f'protein_class_{k}.csv')\n",
    "    \n",
    "    learn.save(f'SEResNext50_{k}_{phase}_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'SEResNext50_2_3_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    }
   ],
   "source": [
    "pred = make_prediction()\n",
    "save_pred(pred, th_t, fname=f'protein_class_{k}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "def sigmoid_np(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "preds,y = learn.TTA(n_aug=16)\n",
    "preds = np.stack(preds, axis=-1)\n",
    "preds = sigmoid_np(preds)\n",
    "pred = preds.max(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def F1_soft(preds,targs,th=0.5,d=50.0):\n",
    "    preds = sigmoid_np(d*(preds - th))\n",
    "    targs = targs.astype(np.float)\n",
    "    score = 2.0*(preds*targs).sum(axis=0)/((preds+targs).sum(axis=0) + 1e-6)\n",
    "    return score\n",
    "\n",
    "def fit_val(x,y):\n",
    "    params = 0.5*np.ones(len(name_label_dict))\n",
    "    wd = 1e-5\n",
    "    error = lambda p: np.concatenate((F1_soft(x,y,p) - 1.0,\n",
    "                                      wd*(p - 0.5)), axis=None)\n",
    "    p, success = opt.leastsq(error, params)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds:  [0.67447 0.77441 0.6432  0.71032 0.7633  0.58246 0.59099 0.61067 0.59715 0.83648 0.47122 0.71517 0.73005\n",
      " 0.91396 0.72482 0.44042 0.88081 0.75626 0.519   0.60685 0.80563 0.61776 0.75221 0.76512 0.74962 0.60664\n",
      " 0.71887 0.63454]\n",
      "F1 macro:  0.7140915172064203\n",
      "F1 macro (th = 0.5):  0.6832496715576231\n",
      "F1 micro:  0.7769354338697405\n"
     ]
    }
   ],
   "source": [
    "th = fit_val(pred,y)\n",
    "th[th<0.1] = 0.1\n",
    "print('Thresholds: ',th)\n",
    "print('F1 macro: ',f1_score(y, pred>th, average='macro'))\n",
    "print('F1 macro (th = 0.5): ',f1_score(y, pred>0.5, average='macro'))\n",
    "print('F1 micro: ',f1_score(y, pred>th, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractions:  [0.43182 0.04031 0.11328 0.04902 0.05763 0.08668 0.0318  0.08782 0.00265 0.00104 0.00104 0.0318  0.02347\n",
      " 0.01722 0.037   0.00123 0.0158  0.00823 0.03341 0.04325 0.00729 0.12416 0.02697 0.0987  0.00833 0.30803\n",
      " 0.01306 0.00028]\n",
      "Fractions (true):  [0.41355 0.04154 0.11772 0.05139 0.06057 0.08167 0.03322 0.09217 0.00199 0.00151 0.00095 0.03615 0.02423\n",
      " 0.01845 0.03511 0.00076 0.01902 0.00757 0.03    0.04902 0.00577 0.12321 0.02725 0.09577 0.01107 0.26517\n",
      " 0.01107 0.00066]\n"
     ]
    }
   ],
   "source": [
    "print('Fractions: ',(pred > th).mean(axis=0))\n",
    "print('Fractions (true): ',(y > th).mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractions:  [0.46804 0.04478 0.09306 0.03786 0.05264 0.0746  0.02991 0.07375 0.00154 0.00111 0.00051 0.03717 0.03179\n",
      " 0.0282  0.05042 0.00009 0.03837 0.02239 0.02589 0.03965 0.00667 0.15023 0.03076 0.11152 0.00872 0.35208\n",
      " 0.02042 0.00077]\n"
     ]
    }
   ],
   "source": [
    "th_t = np.array([0.565,0.39,0.55,0.345,0.33,0.39,0.33,0.45,0.38,0.39,\n",
    "               0.34,0.42,0.31,0.38,0.49,0.50,0.38,0.43,0.46,0.40,\n",
    "               0.39,0.505,0.37,0.47,0.41,0.545,0.32,0.1])\n",
    "print('Fractions: ',(pred_t > th_t).mean(axis=0))\n",
    "save_pred(pred_t,th_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "preds_t,y_t = learn.TTA(n_aug=16,is_test=True)\n",
    "preds_t = np.stack(preds_t, axis=-1)\n",
    "preds_t = sigmoid_np(preds_t)\n",
    "pred_t = preds_t.max(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lb_prob = [\n",
    " 0.362397820,0.043841336,0.075268817,0.059322034,0.075268817,\n",
    " 0.075268817,0.043841336,0.075268817,0.010000000,0.010000000,\n",
    " 0.010000000,0.043841336,0.043841336,0.014198783,0.043841336,\n",
    " 0.010000000,0.028806584,0.014198783,0.028806584,0.059322034,\n",
    " 0.010000000,0.126126126,0.028806584,0.075268817,0.010000000,\n",
    " 0.222493880,0.028806584,0.010000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Count_soft(preds,th=0.5,d=50.0):\n",
    "    preds = sigmoid_np(d*(preds - th))\n",
    "    return preds.mean(axis=0)\n",
    "\n",
    "def fit_test(x,y):\n",
    "    params = 0.5*np.ones(len(name_label_dict))\n",
    "    wd = 1e-5\n",
    "    error = lambda p: np.concatenate((Count_soft(x,p) - y,\n",
    "                                      wd*(p - 0.5)), axis=None)\n",
    "    p, success = opt.leastsq(error, params)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds:  [0.80374 0.49925 0.76483 0.21822 0.24233 0.49543 0.26365 0.54937 0.10824 0.1054  0.1     0.42081 0.25919\n",
      " 0.89889 0.77842 0.1     0.69168 0.86501 0.56459 0.292   0.35843 0.70467 0.5345  0.81766 0.45866 0.80764\n",
      " 0.27445 0.1    ]\n",
      "Fractions:  [0.36361 0.04384 0.07546 0.05871 0.07426 0.0752  0.0435  0.07503 0.00461 0.00419 0.00171 0.04392 0.04341\n",
      " 0.01461 0.04384 0.00205 0.0288  0.01461 0.02888 0.05922 0.01008 0.1269  0.02888 0.0758  0.01    0.22466\n",
      " 0.0288  0.00137]\n",
      "Fractions (th = 0.5):  [0.52777 0.04384 0.11571 0.0382  0.04974 0.07469 0.02512 0.08067 0.00162 0.00103 0.00068 0.03991 0.02863\n",
      " 0.0282  0.05461 0.00009 0.03863 0.02495 0.03179 0.04187 0.00795 0.17886 0.02991 0.1275  0.00974 0.41386\n",
      " 0.01846 0.00009]\n"
     ]
    }
   ],
   "source": [
    "th_t = fit_test(pred_t,lb_prob)\n",
    "th_t[th_t<0.1] = 0.1\n",
    "print('Thresholds: ',th_t)\n",
    "print('Fractions: ',(pred_t > th_t).mean(axis=0))\n",
    "print('Fractions (th = 0.5): ',(pred_t > 0.5).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_pred(pred_t,th_t,'protein_classification_f.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_pred(pred_t,th,'protein_classification_v.csv')\n",
    "save_pred(pred_t,0.5,'protein_classification_05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class_list = [8,9,10,15,20,24,27]\n",
    "for i in class_list:\n",
    "    th_t[i] = th[i]\n",
    "save_pred(pred_t,th_t,'protein_classification_c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([12885.,  1254.,  3621.,  1561.,  1858.,  2513.,  1008.,  2822.,    53.,    45.,    28.,  1093.,\n",
       "          688.,   537.,  1066.,    21.,   530.,   210.,   902.,  1482.,   172.,  3777.,   802.,  2965.,\n",
       "          322.,  8228.,   328.,    11.]),\n",
       " array([0.41468, 0.04036, 0.11654, 0.05024, 0.0598 , 0.08088, 0.03244, 0.09082, 0.00171, 0.00145, 0.0009 ,\n",
       "        0.03518, 0.02214, 0.01728, 0.03431, 0.00068, 0.01706, 0.00676, 0.02903, 0.0477 , 0.00554, 0.12156,\n",
       "        0.02581, 0.09542, 0.01036, 0.2648 , 0.01056, 0.00035]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(LABELS).set_index('Id')\n",
    "label_count = np.zeros(len(name_label_dict))\n",
    "for label in labels['Target']:\n",
    "    l = [int(i) for i in label.split()]\n",
    "    label_count += np.eye(len(name_label_dict))[l].sum(axis=0)\n",
    "label_fraction = label_count.astype(np.float)/len(labels)\n",
    "label_count, label_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds:  [0.7347  0.56408 0.50024 0.30176 0.36257 0.45713 0.37413 0.41914 0.50788 0.35831 0.2295  0.57945 0.64883\n",
      " 0.80423 0.91007 0.24861 0.91427 0.97507 0.55993 0.41841 0.70555 0.72181 0.60697 0.7074  0.41463 0.76006\n",
      " 0.84881 0.27531]\n",
      "Fractions:  [0.41736 0.04008 0.11562 0.04982 0.05931 0.08041 0.0317  0.09075 0.00162 0.00137 0.00085 0.03512 0.02196\n",
      " 0.01718 0.03563 0.0006  0.01718 0.00829 0.02897 0.0482  0.00547 0.12177 0.02615 0.0958  0.01025 0.26782\n",
      " 0.01051 0.00034]\n"
     ]
    }
   ],
   "source": [
    "th_t = fit_test(pred_t,label_fraction)\n",
    "th_t[th_t<0.05] = 0.05\n",
    "print('Thresholds: ',th_t)\n",
    "print('Fractions: ',(pred_t > th_t).mean(axis=0))\n",
    "save_pred(pred_t,th_t,'protein_classification_t.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Folds Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "pred_array = np.zeros((11702, 28),dtype=float)\n",
    "\n",
    "for k in range(folds):\n",
    "    learn.load(f'SEResNext50_{k}_3_cylic')\n",
    "    preds_t,y_t = learn.TTA(n_aug=16, is_test=True)\n",
    "    preds_t = np.stack(preds_t, axis=-1)\n",
    "    preds_t = sigmoid_np(preds_t)\n",
    "    pred_t = preds_t.max(axis=-1)\n",
    "    pred_array = pred_t + pred_array\n",
    "\n",
    "pred_array = pred_array / folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40326, 0.04375, 0.06888, 0.0705 , 0.08067, 0.10144, 0.05486, 0.0899 , 0.00094, 0.00043, 0.00034,\n",
       "       0.0482 , 0.04486, 0.01863, 0.04102, 0.     , 0.03598, 0.01752, 0.02239, 0.06614, 0.00461, 0.11451,\n",
       "       0.03222, 0.09434, 0.0153 , 0.19458, 0.03247, 0.01213])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_t = np.array([0.565,0.39,0.55,0.345,0.33,0.39,0.33,0.45,0.38,0.39,\n",
    "               0.34,0.42,0.31,0.38,0.49,0.50,0.38,0.43,0.46,0.40,\n",
    "               0.39,0.505,0.37,0.47,0.41,0.545,0.32,0.1])\n",
    "(pred_array > th_t).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pred(pred_array,th_t,'protein_classification_mfolds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_list = []\n",
    "# for line in pred_array:\n",
    "#     s = ' '.join(list([str(i) for i in np.nonzero(line>th_t)[0]]))\n",
    "#     pred_list.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df = pd.read_csv(SAMPLE)\n",
    "# sample_list = list(sample_df.Id)\n",
    "# pred_dic = dict((key, value) for (key, value) \n",
    "#                 in zip(learn.data.test_ds.fnames,pred_list))\n",
    "# pred_list_cor = [pred_dic[id] for id in sample_list]\n",
    "# df = pd.DataFrame({'Id':sample_list,'Predicted':pred_list_cor})\n",
    "# df.to_csv('protein_classification.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 (pretrained)\n",
    "1. lr=1e-2\n",
    "1. learn.fit(lrs/4,4,cycle_len=2,use_clr=(10,20), best_save_name=f'{arch}_{phase}')\n",
    "1. learn.fit(lrs/4,2,cycle_len=23,use_clr=(10,20), best_save_name=f'{arch}_{phase}')\n",
    "1. learn.fit(lrs/8,1,cycle_len=10,use_clr=(5,20), best_save_name=f'{arch}_{phase}')\n",
    "\n",
    "LB Score: 0.50 (modelname:<function resnet50 at 0x7f41f50d3400> _3), \n",
    "\n",
    "Resnet50 - 0.7056019664330974 0.6823389611938516, LB:0.503\n",
    "\n",
    "SEResNext50\n",
    "1. lr=1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other ideas\n",
    "1. Set gradient clipping to 1.0 instead of 0.25\n",
    "1. Try another Focal Loss implementation\n",
    "1. Increase batch size - bs=8 so far means 7GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def _init_(self, num_classes=28):\n",
    "        super()._init_()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, pred, targ):\n",
    "        t = targ\n",
    "        x = pred\n",
    "        w = self.get_weight(x,t)\n",
    "        return F.binary_cross_entropy_with_logits(x, t, w, \n",
    "                          size_average=False)/self.num_classes\n",
    "    \n",
    "    def get_weight(self,x,t):\n",
    "        alpha,gamma = 0.25,2.\n",
    "        p = x.sigmoid()\n",
    "        pt = p*t + (1-p)*(1-t)\n",
    "        w = alpha*t + (1-alpha)*(1-t)\n",
    "        return w * (1-pt).pow(gamma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
