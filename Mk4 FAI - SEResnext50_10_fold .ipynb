{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNext50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### House Keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './'\n",
    "TRAIN = 'data/train/'\n",
    "TEST = 'data/test/'\n",
    "LABELS = 'data/train.csv'\n",
    "SAMPLE = 'data/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = list({f[:36] for f in os.listdir(TRAIN)})\n",
    "test_names = list({f[:36] for f in os.listdir(TEST)})\n",
    "tr_n, val_n = train_test_split(train_names, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_rgby(path,id): \n",
    "    colors = ['red','green','blue','yellow']\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    img = [cv2.imread(os.path.join(path, id+'_'+color+'.png'), flags).astype(np.float32)/255\n",
    "           for color in colors]\n",
    "    return np.stack(img, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_label_dict = {\n",
    "0:  'Nucleoplasm',\n",
    "1:  'Nuclear membrane',\n",
    "2:  'Nucleoli',   \n",
    "3:  'Nucleoli fibrillar center',\n",
    "4:  'Nuclear speckles',\n",
    "5:  'Nuclear bodies',\n",
    "6:  'Endoplasmic reticulum',   \n",
    "7:  'Golgi apparatus',\n",
    "8:  'Peroxisomes',\n",
    "9:  'Endosomes',\n",
    "10:  'Lysosomes',\n",
    "11:  'Intermediate filaments',\n",
    "12:  'Actin filaments',\n",
    "13:  'Focal adhesion sites',   \n",
    "14:  'Microtubules',\n",
    "15:  'Microtubule ends',  \n",
    "16:  'Cytokinetic bridge',   \n",
    "17:  'Mitotic spindle',\n",
    "18:  'Microtubule organizing center',  \n",
    "19:  'Centrosome',\n",
    "20:  'Lipid droplets',\n",
    "21:  'Plasma membrane',   \n",
    "22:  'Cell junctions', \n",
    "23:  'Mitochondria',\n",
    "24:  'Aggresome',\n",
    "25:  'Cytosol',\n",
    "26:  'Cytoplasmic bodies',   \n",
    "27:  'Rods & rings' }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Objects & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pdFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, path, transform):\n",
    "        self.labels = pd.read_csv(LABELS).set_index('Id')\n",
    "        self.labels['Target'] = [[int(i) for i in s.split()] for s in self.labels['Target']]\n",
    "        super().__init__(fnames, transform, path)\n",
    "    \n",
    "    def get_x(self, i):\n",
    "        img = open_rgby(self.path,self.fnames[i])\n",
    "        if self.sz == 512: return img \n",
    "        else: return cv2.resize(img, (self.sz, self.sz),cv2.INTER_AREA)\n",
    "    \n",
    "    def get_y(self, i):\n",
    "        if(self.path == TEST): return np.zeros(len(name_label_dict),dtype=np.int)\n",
    "        else:\n",
    "            labels = self.labels.loc[self.fnames[i]]['Target']\n",
    "            return np.eye(len(name_label_dict),dtype=np.float)[labels].sum(axis=0)\n",
    "        \n",
    "    @property\n",
    "    def is_multi(self): return True\n",
    "    @property\n",
    "    def is_reg(self):return True\n",
    "    #this flag is set to remove the output sigmoid that allows log(sigmoid) optimization\n",
    "    #of the numerical stability of the loss function\n",
    "    \n",
    "    def get_c(self): return len(name_label_dict) #number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz,bs):\n",
    "    #data augmentation\n",
    "    aug_tfms = [RandomRotate(30, tfm_y=TfmType.NO),\n",
    "                RandomDihedral(tfm_y=TfmType.NO)]\n",
    "    stats = A([0.00505, 0.00331, 0.00344, 0.00519], [0.10038, 0.08131, 0.08284, 0.10179])\n",
    "    tfms = tfms_from_stats(stats, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, \n",
    "                aug_tfms=aug_tfms)\n",
    "    ds = ImageData.get_ds(pdFilesDataset, (tr_n[:-(len(tr_n)%bs)],TRAIN), \n",
    "                (val_n,TRAIN), tfms, test=(test_names,TEST))\n",
    "    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCalculating the averages\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Calculating the averages\n",
    "'''\n",
    "\n",
    "# x_tot = np.zeros(4)\n",
    "# x2_tot = np.zeros(4)\n",
    "# for x,y in iter(md.trn_dl):\n",
    "#     tmp =  md.trn_ds.denorm(x).reshape(16,-1)\n",
    "#     x = md.trn_ds.denorm(x).reshape(-1,4)\n",
    "#     x_tot += x.mean(axis=0)\n",
    "#     x2_tot += (x**2).mean(axis=0)\n",
    "\n",
    "# channel_avr = x_tot/len(md.trn_dl)\n",
    "# channel_std = np.sqrt(x2_tot/len(md.trn_dl) - channel_avr**2)\n",
    "# channel_avr,channel_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()\n",
    "    \n",
    "def acc(preds,targs,thresh=0.0):\n",
    "    preds = (preds > thresh).int()\n",
    "    targs = targs.int()\n",
    "    return (preds==targs).float().mean()\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    y_true = y_true.type(torch.FloatTensor).cuda()\n",
    "    tp = torch.sum(y_true*y_pred)\n",
    "    tn = torch.sum((1-y_true)*(1-y_pred))\n",
    "    fp = torch.sum((1-y_true)*y_pred)\n",
    "    fn = torch.sum((y_true*(1-y_pred)))\n",
    "    \n",
    "    p = tp / (tp + fp + epsilon)\n",
    "    r = tp / (tp + fn + epsilon)\n",
    "    f1 = 2*p*r / (p+r+epsilon)\n",
    "    f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1), f1)\n",
    "    return 2 - torch.mean(f1)\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    y_true = y_true.type(torch.FloatTensor).cuda()\n",
    "    score = torch.sum(2.0*(y_pred*y_true))/torch.sum((y_pred+y_true) + 1e-7)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as opt\n",
    "\n",
    "def sigmoid_np(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def F1_soft(preds,targs,th=0.5,d=50.0):\n",
    "    preds = sigmoid_np(d*(preds - th))\n",
    "    targs = targs.astype(np.float)\n",
    "    score = 2.0*(preds*targs).sum(axis=0)/((preds+targs).sum(axis=0) + 1e-6)\n",
    "    return score\n",
    "\n",
    "def fit_val(x,y):\n",
    "    params = 0.5*np.ones(len(name_label_dict))\n",
    "    wd = 1e-5\n",
    "    error = lambda p: np.concatenate((F1_soft(x,y,p) - 1.0,\n",
    "                                      wd*(p - 0.5)), axis=None)\n",
    "    p, success = opt.leastsq(error, params)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(pred, y):\n",
    "    preds,y = learn.TTA(n_aug=8)\n",
    "    preds = np.stack(preds, axis=-1)\n",
    "    preds = sigmoid_np(preds)\n",
    "    pred = preds.max(axis=-1)\n",
    "    \n",
    "    th = fit_val(pred,y)\n",
    "    th[th<0.1] = 0.1\n",
    "    print('Thresholds: ',th)\n",
    "    print('F1 macro: ',f1_score(y, pred>th, average='macro'))\n",
    "    print('F1 macro (th = 0.5): ',f1_score(y, pred>0.5, average='macro'))\n",
    "    print('F1 micro: ',f1_score(y, pred>th, average='micro'))\n",
    "    \n",
    "    print('Fractions: ',(pred > th).mean(axis=0))\n",
    "    print('Fractions (true): ',(y > th).mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvnetBuilder_custom():\n",
    "    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, \n",
    "                 custom_head=None, pretrained=True):\n",
    "        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n",
    "        if xtra_fc is None: xtra_fc = [512]\n",
    "        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n",
    "        self.ps,self.xtra_fc = ps,xtra_fc\n",
    "\n",
    "        if f in model_meta: cut,self.lr_cut = model_meta[f]\n",
    "        else: cut,self.lr_cut = 0,0\n",
    "        cut-=xtra_cut\n",
    "        layers = cut_model(f(pretrained), cut)\n",
    "        \n",
    "        #replace first convolutional layer by 4->64 while keeping corresponding weights\n",
    "        #and initializing new weights with zeros\n",
    "        #####################################################\n",
    "        w = layers[0].weight\n",
    "        layers[0] = nn.Conv2d(4,64,kernel_size=(7,7),stride=(2,2),padding=(3, 3), bias=False)\n",
    "        layers[0].weight = torch.nn.Parameter(torch.cat((w,torch.zeros(64,1,7,7)),dim=1))\n",
    "        #####################################################\n",
    "        \n",
    "        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n",
    "        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n",
    "        self.top_model = nn.Sequential(*layers)\n",
    "\n",
    "        n_fc = len(self.xtra_fc)+1\n",
    "        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n",
    "\n",
    "        if custom_head: fc_layers = [custom_head]\n",
    "        else: fc_layers = self.get_fc_layers()\n",
    "        self.n_fc = len(fc_layers)\n",
    "        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n",
    "        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n",
    "        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))\n",
    "\n",
    "    @property\n",
    "    def name(self): return f'{self.f.__name__}_{self.xtra_cut}'\n",
    "\n",
    "    def create_fc_layer(self, ni, nf, p, actn=None):\n",
    "        res=[nn.BatchNorm1d(num_features=ni)]\n",
    "        if p: res.append(nn.Dropout(p=p))\n",
    "        res.append(nn.Linear(in_features=ni, out_features=nf))\n",
    "        if actn: res.append(actn)\n",
    "        return res\n",
    "\n",
    "    def get_fc_layers(self):\n",
    "        res=[]\n",
    "        ni=self.nf\n",
    "        for i,nf in enumerate(self.xtra_fc):\n",
    "            res += self.create_fc_layer(ni, nf, p=self.ps[i], actn=nn.ReLU())\n",
    "            ni=nf\n",
    "        final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax()\n",
    "        if self.is_reg: final_actn = None\n",
    "        res += self.create_fc_layer(ni, self.c, p=self.ps[-1], actn=final_actn)\n",
    "        return res\n",
    "\n",
    "    def get_layer_groups(self, do_fc=False):\n",
    "        if do_fc:\n",
    "            return [self.fc_model]\n",
    "        idxs = [self.lr_cut]\n",
    "        c = children(self.top_model)\n",
    "        if len(c)==3: c = children(c[0])+c[1:]\n",
    "        lgs = list(split_by_idxs(c,idxs))\n",
    "        return lgs+[self.fc_model]\n",
    "    \n",
    "class ConvLearner(Learner):\n",
    "    def __init__(self, data, models, precompute=False, **kwargs):\n",
    "        self.precompute = False\n",
    "        super().__init__(data, models, **kwargs)\n",
    "        if hasattr(data, 'is_multi') and not data.is_reg and self.metrics is None:\n",
    "            self.metrics = [accuracy_thresh(0.5)] if self.data.is_multi else [accuracy]\n",
    "        if precompute: self.save_fc1()\n",
    "        self.freeze()\n",
    "        self.precompute = precompute\n",
    "\n",
    "    def _get_crit(self, data):\n",
    "        if not hasattr(data, 'is_multi'): return super()._get_crit(data)\n",
    "\n",
    "        return F.l1_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n",
    "\n",
    "    @classmethod\n",
    "    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n",
    "                   pretrained=True, **kwargs):\n",
    "        models = ConvnetBuilder_custom(f, data.c, data.is_multi, data.is_reg,\n",
    "            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n",
    "        return cls(data, models, precompute, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def lsuv_learner(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n",
    "                  needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False, **kwargs):\n",
    "        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n",
    "            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=False)\n",
    "        convlearn=cls(data, models, precompute, **kwargs)\n",
    "        convlearn.lsuv_init()\n",
    "        return convlearn\n",
    "    \n",
    "    @property\n",
    "    def model(self): return self.models.fc_model if self.precompute else self.models.model\n",
    "    \n",
    "    def half(self):\n",
    "        if self.fp16: return\n",
    "        self.fp16 = True\n",
    "        if type(self.model) != FP16: self.models.model = FP16(self.model)\n",
    "        if not isinstance(self.models.fc_model, FP16): self.models.fc_model = FP16(self.models.fc_model)\n",
    "    def float(self):\n",
    "        if not self.fp16: return\n",
    "        self.fp16 = False\n",
    "        if type(self.models.model) == FP16: self.models.model = self.model.module.float()\n",
    "        if type(self.models.fc_model) == FP16: self.models.fc_model = self.models.fc_model.module.float()\n",
    "\n",
    "    @property\n",
    "    def data(self): return self.fc_data if self.precompute else self.data_\n",
    "\n",
    "    def create_empty_bcolz(self, n, name):\n",
    "        return bcolz.carray(np.zeros((0,n), np.float32), chunklen=1, mode='w', rootdir=name)\n",
    "\n",
    "    def set_data(self, data, precompute=False):\n",
    "        super().set_data(data)\n",
    "        if precompute:\n",
    "            self.unfreeze()\n",
    "            self.save_fc1()\n",
    "            self.freeze()\n",
    "            self.precompute = True\n",
    "        else:\n",
    "            self.freeze()\n",
    "\n",
    "    def get_layer_groups(self):\n",
    "        return self.models.get_layer_groups(self.precompute)\n",
    "\n",
    "    def summary(self):\n",
    "        precompute = self.precompute\n",
    "        self.precompute = False\n",
    "        res = super().summary()\n",
    "        self.precompute = precompute\n",
    "        return res\n",
    "\n",
    "    def get_activations(self, force=False):\n",
    "        tmpl = f'_{self.models.name}_{self.data.sz}.bc'\n",
    "        # TODO: Somehow check that directory names haven't changed (e.g. added test set)\n",
    "        names = [os.path.join(self.tmp_path, p+tmpl) for p in ('x_act', 'x_act_val', 'x_act_test')]\n",
    "        if os.path.exists(names[0]) and not force:\n",
    "            self.activations = [bcolz.open(p) for p in names]\n",
    "        else:\n",
    "            self.activations = [self.create_empty_bcolz(self.models.nf,n) for n in names]\n",
    "\n",
    "    def save_fc1(self):\n",
    "        self.get_activations()\n",
    "        act, val_act, test_act = self.activations\n",
    "        m=self.models.top_model\n",
    "        if len(self.activations[0])!=len(self.data.trn_ds):\n",
    "            predict_to_bcolz(m, self.data.fix_dl, act)\n",
    "        if len(self.activations[1])!=len(self.data.val_ds):\n",
    "            predict_to_bcolz(m, self.data.val_dl, val_act)\n",
    "        if self.data.test_dl and (len(self.activations[2])!=len(self.data.test_ds)):\n",
    "            if self.data.test_dl: predict_to_bcolz(m, self.data.test_dl, test_act)\n",
    "\n",
    "        self.fc_data = ImageClassifierData.from_arrays(self.data.path,\n",
    "                (act, self.data.trn_y), (val_act, self.data.val_y), self.data.bs, classes=self.data.classes,\n",
    "                test = test_act if self.data.test_dl else None, num_workers=8)\n",
    "\n",
    "    def freeze(self):\n",
    "        self.freeze_to(-1)\n",
    "\n",
    "    def unfreeze(self):\n",
    "        self.freeze_to(0)\n",
    "        self.precompute = False\n",
    "\n",
    "    def predict_array(self, arr):\n",
    "        precompute = self.precompute\n",
    "        self.precompute = False\n",
    "        pred = super().predict_array(arr)\n",
    "        self.precompute = precompute\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SE Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_settings = {\n",
    "    'se_resnext50_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext101_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    Bottleneck for SENet154.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
    "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
    "    (the latter is used in the torchvision implementation of ResNet).\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
    "                               stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
    "                               groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.drop1 = nn.Dropout2d(0.2)\n",
    "        self.drop2 = nn.Dropout2d(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SENet(nn.Module):\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.5,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "#         self.last_linear = nn.Linear(512*16, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def initialize_pretrained_model(model, num_classes, settings):\n",
    "    assert num_classes == settings['num_classes'], \\\n",
    "        'num_classes should be {}, but is {}'.format(\n",
    "            settings['num_classes'], num_classes)\n",
    "    model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "    model.input_space = settings['input_space']\n",
    "    model.input_size = settings['input_size']\n",
    "    model.input_range = settings['input_range']\n",
    "    model.mean = settings['mean']\n",
    "    model.std = settings['std']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNextConvBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNextConvBuilder(ConvnetBuilder_custom):\n",
    "    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, \n",
    "                 custom_head=None, pretrained=True):\n",
    "        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n",
    "        if xtra_fc is None: xtra_fc = [512]\n",
    "        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n",
    "        self.ps,self.xtra_fc = ps,xtra_fc\n",
    "\n",
    "        if f in model_meta: cut,self.lr_cut = model_meta[f]\n",
    "        else: cut,self.lr_cut = 8,6\n",
    "        cut-=xtra_cut\n",
    "        layers = cut_model(f(), 5)\n",
    "        \n",
    "        #replace first convolutional layer by 4->64 while keeping corresponding weights\n",
    "        #and initializing new weights with zeros\n",
    "        #####################################################\n",
    "        w = layers[0].conv1.weight\n",
    "        layers[0].conv1 = nn.Conv2d(4,64,kernel_size=(7,7),stride=(2,2),padding=(3, 3), bias=False)\n",
    "        layers[0].conv1.weight = torch.nn.Parameter(torch.cat((w,torch.zeros(64,1,7,7)),dim=1))\n",
    "        #####################################################\n",
    "        \n",
    "        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n",
    "        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n",
    "        self.top_model = nn.Sequential(*layers)\n",
    "\n",
    "        n_fc = len(self.xtra_fc)+1\n",
    "        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n",
    "\n",
    "        if custom_head: fc_layers = [custom_head]\n",
    "        else: fc_layers = self.get_fc_layers()\n",
    "        self.n_fc = len(fc_layers)\n",
    "        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n",
    "        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n",
    "        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))\n",
    "\n",
    "class ResNextConv(ConvLearner):\n",
    "        @classmethod\n",
    "        def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n",
    "                   pretrained=True, **kwargs):\n",
    "            models = ResNextConvBuilder(f, data.c, data.is_multi, data.is_reg,\n",
    "            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n",
    "            return cls(data, models, precompute, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n",
    "                  dropout_p=0.5, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnext50_model(md):\n",
    "    learn = ResNextConv.pretrained(se_resnext50_32x4d, md, ps=0.5) #dropout 50%\n",
    "    learn.opt_fn = optim.Adam\n",
    "    learn.crit = FocalLoss()\n",
    "    learn.metrics = [acc, f1_metric]\n",
    "    learn.clip = 1.0\n",
    "    return learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test & Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bs = 8\n",
    "sz = 512\n",
    "nw = 6\n",
    "md = get_data(sz,bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    }
   ],
   "source": [
    "learn = get_resnext50_model(md)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.lr_find2()\n",
    "# learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "lrs=np.array([lr/10,lr/3,lr])\n",
    "model_id = 'SEResNext50_Mk1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d63decf64c64b698b87470e752db8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                          \n",
      "    0      1.384055   1.184798   0.948302  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1847979014444536, 0.9483016196211639]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59130dcbdb445da8aeb8a6ff02abe1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                          \n",
      "    0      1.078669   0.966236   0.956725  \n",
      "    1      1.059594   0.892402   0.959046                      \n",
      "    2      0.935106   0.794946   0.962999                      \n",
      "    3      0.911128   0.754595   0.965102                      \n",
      "    4      0.828862   0.714963   0.966159                      \n",
      "    5      0.769191   0.692742   0.967204                      \n",
      "CPU times: user 6h 34min 25s, sys: 4h 23min 10s, total: 10h 57min 35s\n",
      "Wall time: 2h 46min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "phase = 1\n",
    "learn.unfreeze()\n",
    "learn.fit(lrs/3,3,cycle_len=2,\n",
    "          use_clr=(10,20), \n",
    "          best_save_name=f'{model_id}_{phase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622e0f4eb090477badfa6d88516986c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.803923   0.678944   0.96802   \n",
      "    1      0.783068   0.659938   0.968687                      \n",
      "    2      0.751022   0.641457   0.969767                      \n",
      "    3      0.719631   0.642843   0.969411                      \n",
      "    4      0.768724   0.625307   0.970169                      \n",
      "    5      0.720313   0.616126   0.970514                      \n",
      "    6      0.683994   0.611221   0.970939                      \n",
      "    7      0.677048   0.600325   0.971617                      \n",
      "    8      0.664782   0.594959   0.971835                      \n",
      "    9      0.638504   0.592827   0.972077                      \n",
      "    10     0.647609   0.58502    0.972284                      \n",
      "    11     0.696528   0.587539   0.972134                      \n",
      "    12     0.654107   0.582401   0.972456                      \n",
      "    13     0.667853   0.577229   0.972847                      \n",
      "    14     0.597091   0.572194   0.973088                      \n",
      "    15     0.629614   0.572426   0.972939                      \n",
      "    16     0.621325   0.568628   0.97303                       \n",
      "    17     0.598749   0.564727   0.973651                      \n",
      "    18     0.614315   0.56707    0.97341                       \n",
      "    19     0.581521   0.569853   0.972812                      \n",
      "    20     0.612328   0.560336   0.973651                      \n",
      "    21     0.623136   0.569722   0.973375                      \n",
      "    22     0.580681   0.565911   0.973329                      \n",
      "    23     0.626172   0.568695   0.97349                       \n",
      "    24     0.595337   0.562178   0.973421                      \n",
      "    25     0.582808   0.566312   0.973329                      \n",
      "    26     0.583887   0.559393   0.974134                      \n",
      "    27     0.564763   0.554936   0.973754                      \n",
      "    28     0.553906   0.567135   0.97318                       \n",
      "    29     0.530175   0.55891    0.9738                        \n",
      "    30     0.590292   0.56298    0.974122                      \n",
      "    31     0.560593   0.553654   0.974226                      \n",
      "    32     0.543306   0.558349   0.974157                      \n",
      "    33     0.519412   0.56196    0.974065                      \n",
      "    34     0.513873   0.558538   0.973938                      \n",
      "    35     0.525148   0.568876   0.973697                      \n",
      "    36     0.500936   0.557138   0.974271                      \n",
      "    37     0.513994   0.551314   0.974501                      \n",
      "    38     0.514559   0.556947   0.974547                      \n",
      "    39     0.479037   0.562603   0.973777                      \n",
      "    40     0.485516   0.563521   0.973731                      \n",
      "    41     0.485141   0.564062   0.974271                      \n",
      "    42     0.489808   0.557644   0.974375                      \n",
      "    43     0.496916   0.565681   0.973536                      \n",
      "    44     0.449701   0.560623   0.973835                      \n",
      "    45     0.46431    0.573054   0.974582                      \n",
      "CPU times: user 2d 2h 6min 9s, sys: 1d 9h 9min 56s, total: 3d 11h 16min 5s\n",
      "Wall time: 21h 30min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "phase = 2\n",
    "learn.fit(lrs/5,2,cycle_len=23,\n",
    "          use_clr=(10,20),\n",
    "          best_save_name=f'{model_id}_{phase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7502511f2844beb25e2b1b032172e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.468346   0.562558   0.974203  \n",
      "    1      0.431962   0.557532   0.974478                      \n",
      "    2      0.449179   0.566225   0.97457                       \n",
      "    3      0.445568   0.566574   0.973984                      \n",
      "    4      0.445385   0.568733   0.974271                      \n",
      "    5      0.449579   0.570855   0.974134                      \n",
      "    6      0.409382   0.571065   0.974157                      \n",
      "    7      0.435574   0.557584   0.974478                      \n",
      "CPU times: user 8h 47min 8s, sys: 5h 53min 29s, total: 14h 40min 38s\n",
      "Wall time: 3h 42min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "phase = 3\n",
    "learn.fit(lrs/9,1,cycle_len=8,\n",
    "          use_clr=(5,20),\n",
    "          best_save_name=f'{model_id}_{phase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48ccd3769b8440ca351ed590c5c050a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.417849   0.576096   0.974271  \n",
      "    1      0.435696   0.574954   0.974375                      \n",
      "    2      0.413814   0.568115   0.974421                      \n",
      "    3      0.438606   0.582702   0.97418                       \n",
      "    4      0.421163   0.572526   0.974421                      \n",
      "CPU times: user 5h 29min 37s, sys: 3h 40min 41s, total: 9h 10min 19s\n",
      "Wall time: 2h 18min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "phase = 4\n",
    "learn.fit(lrs/18,1,cycle_len=5,\n",
    "          use_clr=(5,20),\n",
    "          best_save_name=f'{model_id}_{phase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(f'{model_id}_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified KFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "folds = 10\n",
    "train_folds = []\n",
    "val_folds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folds():\n",
    "    skf = StratifiedKFold(n_splits=folds, random_state=33, shuffle=True)\n",
    "    \n",
    "    train_names = list({f[:36] for f in os.listdir(TRAIN)})\n",
    "    test_names = list({f[:36] for f in os.listdir(TEST)})\n",
    "    trn_df = pd.read_csv('data/train.csv')\n",
    "    \n",
    "    for train_index, evaluate_index in skf.split(trn_df.index.values, trn_df.Target):\n",
    "        trn_value = trn_df.iloc[train_index]\n",
    "        val_value = trn_df.iloc[evaluate_index]\n",
    "        train_folds.append(trn_value)\n",
    "        val_folds.append(val_value)\n",
    "        print(train_index.shape, evaluate_index.shape)\n",
    "    \n",
    "    for i in range(folds):\n",
    "        train_folds[i].to_csv(f'data/trn_folds_{i}')\n",
    "        val_folds[i].to_csv(f'data/val_folds_{i}')\n",
    "\n",
    "def load_folds():\n",
    "    for i in range(folds):\n",
    "        train_folds.append(pd.read_csv(f'data/trn_folds_{i}'))\n",
    "        val_folds.append(pd.read_csv(f'data/val_folds_{i}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_folds()\n",
    "load_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(sz, bs, k):\n",
    "    aug_tfms = [RandomRotate(30, tfm_y=TfmType.NO),\n",
    "                RandomDihedral(tfm_y=TfmType.NO),\n",
    "                RandomLighting(0.05, 0.05, tfm_y=TfmType.NO)]\n",
    "    \n",
    "    stats = A([0.00505, 0.00331, 0.00344, 0.00519], [0.10038, 0.08131, 0.08284, 0.10179])\n",
    "    tfms = tfms_from_stats(stats, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, \n",
    "                aug_tfms=aug_tfms)\n",
    "    \n",
    "    trn_x = list(train_folds[k]['Id'])\n",
    "    val_x = list(val_folds[k]['Id'])\n",
    "    \n",
    "    if len(trn_x)%bs == 0:\n",
    "        ds = ImageData.get_ds(pdFilesDataset, (trn_x,TRAIN), \n",
    "                (val_x,TRAIN), tfms, test=(test_names,TEST))\n",
    "    else:\n",
    "        ds = ImageData.get_ds(pdFilesDataset, (trn_x[:-(len(trn_x)%bs)],TRAIN), \n",
    "                (val_x,TRAIN), tfms, test=(test_names,TEST))\n",
    "    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_t = np.array([0.565,0.39,0.55,0.345,0.33,0.39,0.33,0.45,0.38,0.39,\n",
    "               0.34,0.42,0.31,0.38,0.49,0.50,0.38,0.43,0.46,0.40,\n",
    "               0.39,0.505,0.37,0.47,0.41,0.545,0.32,0.1])\n",
    "\n",
    "def make_prediction():\n",
    "    preds,y = learn.TTA(n_aug=8, is_test=True)\n",
    "    preds = np.stack(preds, axis=-1)\n",
    "    preds = sigmoid_np(preds)\n",
    "    pred = preds.max(axis=-1)\n",
    "    return pred\n",
    "\n",
    "def save_pred(pred, th=0.5, fname='protein_classification.csv'):\n",
    "    pred_list = []\n",
    "    for line in pred:\n",
    "        s = ' '.join(list([str(i) for i in np.nonzero(line>th)[0]]))\n",
    "        pred_list.append(s)\n",
    "        \n",
    "    sample_df = pd.read_csv(SAMPLE)\n",
    "    sample_list = list(sample_df.Id)\n",
    "    pred_dic = dict((key, value) for (key, value) \n",
    "                in zip(learn.data.test_ds.fnames,pred_list))\n",
    "    pred_list_cor = [pred_dic[id] for id in sample_list]\n",
    "    df = pd.DataFrame({'Id':sample_list,'Predicted':pred_list_cor})\n",
    "    df.to_csv(fname, header=True, index=False)\n",
    "\n",
    "def sigmoid_np(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a single fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "lrs=np.array([lr/10,lr/3,lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 1 Nov "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd2e5f40cac48f08131ebadf3e3f99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.716253   0.610305   0.970637  \n",
      "    1      0.810988   0.682962   0.967485                      \n",
      "    2      0.850518   0.742322   0.964476                      \n",
      "    3      0.856455   0.736685   0.965142                      \n",
      "    4      0.853648   0.745599   0.964345                      \n",
      "    5      0.867788   0.739518   0.964785                      \n",
      "    6      0.798998   0.861175   0.958946                      \n",
      "    7      0.726278   0.691046   0.9667                        \n",
      "    8      0.786308   0.919541   0.95476                       \n",
      "    9      0.739277   0.756989   0.965166                      \n",
      "    10     0.761246   0.67438    0.968365                      \n",
      "    11     0.815754   0.689932   0.970518                      \n",
      "    12     1.19394    1.148847   0.956769                      \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b546d2f42f40fcbfef118ca3d4b5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.77427    0.638722   0.969435  \n",
      "    1      0.744538   0.589413   0.971517                      \n",
      "    2      0.728037   0.584709   0.972302                      \n",
      "    3      0.690187   0.578764   0.972539                      \n",
      "    4      0.657239   0.561222   0.973396                      \n",
      "    5      0.641      0.557375   0.973324                      \n",
      "    6      0.646978   0.555511   0.973645                      \n",
      "    7      0.629134   0.547587   0.973669                      \n",
      "    8      0.640651   0.54753    0.974252                      \n",
      "    9      0.582865   0.542722   0.974288                      \n",
      "    10     0.609905   0.540894   0.974121                      \n",
      "    11     0.58208    0.539542   0.974383                      \n",
      "    12     0.595271   0.554344   0.974097                      \n",
      "    13     0.616822   0.548335   0.97405                       \n",
      "    14     0.609944   0.550125   0.973693                      \n",
      "    15     0.633381   0.543239   0.974145                      \n",
      "    16     0.599074   0.539957   0.974181                      \n",
      "    17     0.595521   0.53306    0.97449                       \n",
      "    18     0.579575   0.529191   0.974787                      \n",
      "    19     0.650073   0.527527   0.974882                      \n",
      "    20     0.555604   0.532115   0.974656                      \n",
      "    21     0.577837   0.529048   0.975001                      \n",
      "    22     0.574762   0.529107   0.975061                      \n",
      "    23     0.541153   0.518642   0.975513                      \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6844b300b6495c89da7230752c9a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.611153   0.536196   0.974347  \n",
      "    1      0.600136   0.529986   0.974573                      \n",
      "    2      0.561485   0.525883   0.97449                       \n",
      "    3      0.624763   0.535126   0.974371                      \n",
      "    4      0.553101   0.528096   0.974549                      \n",
      "    5      0.551494   0.523449   0.975132                      \n",
      "    6      0.548314   0.519562   0.975025                      \n",
      "    7      0.580911   0.528254   0.974668                      \n",
      "    8      0.553009   0.523636   0.97474                       \n",
      "    9      0.510023   0.508556   0.975203                      \n",
      "    10     0.505643   0.512153   0.97518                       \n",
      "    11     0.549881   0.507658   0.975715                      \n",
      "    12     0.55508    0.548513   0.97405                       \n",
      "    13     0.544225   0.52558    0.974621                      \n",
      "    14     0.544936   0.514359   0.975275                      \n",
      "    15     0.488246   0.517938   0.97537                       \n",
      "    16     0.547286   0.512263   0.975548                      \n",
      "    17     0.513765   0.528984   0.975144                      \n",
      "    18     0.549817   0.505315   0.975858                      \n",
      "    19     0.512535   0.509433   0.975513                      \n",
      "    20     0.573269   0.509472   0.975489                      \n",
      "    21     0.525717   0.505473   0.975643                      \n",
      "    22     0.482843   0.512713   0.975477                      \n",
      "    23     0.500588   0.507127   0.975358                      \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46b31a1d0c1443c8f712cd606ef10e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.541758   0.509233   0.975429  \n",
      "    1      0.502344   0.509499   0.97537                       \n",
      "    2      0.48269    0.513051   0.975096                      \n",
      "    3      0.51042    0.506718   0.975762                      \n",
      "    4      0.48576    0.508725   0.975822                      \n",
      "    5      0.461924   0.503836   0.975596                      \n",
      "    6      0.489535   0.503243   0.975477                      \n",
      "    7      0.48139    0.500385   0.975691                      \n",
      "    8      0.468176   0.506697   0.975501                      \n",
      "\n",
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "md = get_fold(sz,bs,3)\n",
    "learn = get_resnext50_model(md)\n",
    "learn.load(f'SEResNext50_Mk1_final')\n",
    "learn.unfreeze()\n",
    "\n",
    "learn.fit(lr, 1, cycle_len=13, wds=1e-4, \n",
    "      use_wd_sched=True, \n",
    "      use_clr_beta=(20, 8, 0.95, 0.85))\n",
    "\n",
    "phase=1\n",
    "learn.fit(lrs/4,2,\n",
    "          cycle_len=12,use_clr=(10,20), \n",
    "          best_save_name=f'SEResNext50_{k}_{phase}_cyclic')\n",
    "\n",
    "phase=2\n",
    "learn.fit(lrs/4,2,\n",
    "          cycle_len=12,use_clr=(10,20), \n",
    "          best_save_name=f'SEResNext50_{k}_{phase}_cyclic')\n",
    "\n",
    "phase=3\n",
    "learn.fit(lrs/16,1,\n",
    "          cycle_len=9,use_clr=(5,20),\n",
    "          best_save_name=f'SEResNext50_{k}_{phase}_cyclic')\n",
    "\n",
    "pred = make_prediction()\n",
    "save_pred(pred, th_t, fname=f'protein_class_{k}.csv')\n",
    "\n",
    "learn.save(f'SEResNext50_{k}_{phase}_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 4th Nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50ef9cfcc874521ade7f1cfb9ad687f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.512558   0.499862   0.975715  \n",
      "    1      0.481082   0.509989   0.975001                      \n",
      "    2      0.515017   0.504424   0.975703                      \n",
      "    3      0.46767    0.507218   0.975739                      \n",
      "    4      0.471899   0.504014   0.976048                      \n",
      "    5      0.451751   0.500838   0.975858                      \n",
      "    6      0.522051   0.507744   0.975965                      \n",
      "    7      0.470991   0.504633   0.975584                      \n",
      "    8      0.471668   0.505629   0.975774                      \n",
      "    9      0.484903   0.511682   0.975525                      \n",
      "    10     0.495392   0.503829   0.97575                       \n",
      "    11     0.484182   0.497827   0.975953                      \n",
      "\n",
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "learn.load(f'SEResNext50_0_{phase}_final')\n",
    "\n",
    "phase=4\n",
    "learn.fit(lrs/16,1,\n",
    "          cycle_len=12,use_clr=(5,20),\n",
    "          best_save_name=f'SEResNext50_{k}_{phase}_cyclic')\n",
    "\n",
    "pred = make_prediction()\n",
    "save_pred(pred, th_t, fname=f'protein_class_{k}.csv')\n",
    "\n",
    "learn.save(f'SEResNext50_{k}_{phase}_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8th Nov - Modeled after FAI Carvana schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### 128 x128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "wd = 1e-7\n",
    "nw = 6\n",
    "lrs=np.array([lr/10,lr/3,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    }
   ],
   "source": [
    "sz = 128\n",
    "bs = 24\n",
    "md = get_fold(sz,bs,6)\n",
    "learn = get_resnext50_model(md)\n",
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058153a9ed864286b918d440cb77d795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc        f1_metric         \n",
      "    0      1.7443     1.374361   0.941175   1.53112   \n",
      "    1      1.528151   1.341383   0.941175   1.545405          \n",
      "    2      1.412082   1.330206   0.941255   1.557025          \n",
      "    3      1.395415   1.326436   0.941369   1.559692          \n",
      "    4      1.417698   1.325366   0.941209   1.571562          \n",
      "    5      1.371706   1.32581    0.941414   1.5591            \n",
      "    6      1.340978   1.319275   0.941608   1.564145          \n",
      "    7      1.358976   1.31806    0.941597   1.563831          \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3180600280737376, 0.9415967870686719, 1.563831495949624]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr,1,wds=wd,cycle_len=8,use_clr=(5,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a97e1ece30c46d0b418eb2bdb7248fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc        f1_metric         \n",
      "    0      1.28251    1.244459   0.946269   1.539671  \n",
      "    1      1.238375   1.199596   0.947625   1.506843          \n",
      "    2      1.206977   1.175167   0.948161   1.496901          \n",
      "    3      1.198032   1.160771   0.948275   1.478878          \n",
      "    4      1.191973   1.1442     0.948628   1.484             \n",
      "    5      1.196366   1.134177   0.949084   1.482743          \n",
      "    6      1.158228   1.1174     0.949471   1.463659          \n",
      "    7      1.144264   1.109263   0.949825   1.447427          \n",
      "    8      1.131458   1.103828   0.949995   1.443733          \n",
      "    9      1.134654   1.100915   0.949984   1.444334          \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.100914532124958, 0.9499840638252603, 1.4443343535455535]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/2, 1, wds=wd, cycle_len=10,use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('128_SeResNext50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### 256 x 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "wd = 1e-7\n",
    "lrs=np.array([lr/10,lr/3,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    }
   ],
   "source": [
    "sz = 256\n",
    "bs = 16\n",
    "md = get_fold(sz,bs,6)\n",
    "learn = get_resnext50_model(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('128_SeResNext50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb5de986f7e4db98ae431aebc3055b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc        f1_metric         \n",
      "    0      1.143997   1.084893   0.951648   1.417219  \n",
      "    1      1.159054   1.065897   0.951705   1.421447          \n",
      "    2      1.146792   1.058936   0.951579   1.411649          \n",
      "    3      1.106668   1.05016    0.952172   1.412086          \n",
      "    4      1.124657   1.045117   0.952457   1.412302          \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0451169985452882, 0.9524569645685684, 1.4123022715301368]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr,1,wds=wd, cycle_len=5,use_clr=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('256_SeResNext50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('256_SeResNext50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac01069f53074a30938c9043a58a4c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc        f1_metric         \n",
      "    0      1.095246   1.005921   0.953243   1.396642  \n",
      "    1      1.043302   0.953969   0.955716   1.373828          \n",
      "    2      1.009086   0.929763   0.956662   1.361759           \n",
      "    3      0.967988   0.889729   0.958599   1.339212           \n",
      "    4      0.967287   0.869817   0.960047   1.336502           \n",
      "    5      0.961438   0.857414   0.960354   1.322094           \n",
      "    6      0.931121   0.84896    0.960286   1.317238           \n",
      "    7      0.923273   0.843716   0.960799   1.318114           \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8437157776527673, 0.9607986583782748, 1.3181138976638151]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/2,1,wds=wd, cycle_len=8,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67589fc66e6b4af28239c740cc59d4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc        f1_metric          \n",
      "    0      0.932448   0.833336   0.961323   1.319736  \n",
      "    1      0.934361   0.831244   0.961414   1.312819           \n",
      "    2      0.900014   0.815094   0.961984   1.299613           \n",
      "    3      0.901654   0.798904   0.96293    1.286361           \n",
      "    4      0.863876   0.791321   0.963009   1.282135           \n",
      "    5      0.868053   0.782043   0.963682   1.27575            \n",
      "    6      0.864361   0.772036   0.963887   1.277563           \n",
      "    7      0.84918    0.772957   0.964081   1.273143           \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7729572782717317, 0.9640806329881757, 1.2731428090827663]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/2,1,wds=wd, cycle_len=8,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('256_SeResNext50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### 512 x 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    }
   ],
   "source": [
    "sz = 512\n",
    "bs = 8\n",
    "md = get_fold(sz,bs,6)\n",
    "learn = get_resnext50_model(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('256_SeResNext50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb03a784c6b94d51babc60793bc5cb82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc        f1_metric          \n",
      "    0      0.968444   0.788095   0.963237   1.312882  \n",
      "    1      0.916194   0.777561   0.964024   1.307866           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7775605917357303, 0.964023652697492, 1.3078659760700948]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr,1, wds=wd, cycle_len=2,use_clr=(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7afa20f7668431a91ac1ad8dff2077c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc        f1_metric          \n",
      "    0      0.843136   0.734978   0.965175   1.27492   \n",
      "    1      0.842354   0.718702   0.966155   1.266053           \n",
      "    2      0.761325   0.718286   0.966257   1.260063           \n",
      "    3      0.809842   0.712653   0.966519   1.261071           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7126528568228263, 0.9665193225292165, 1.2610709356820424]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/10,1, wds=wd,cycle_len=4,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94eded4487284e24a9020f6b6c4b6834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc        f1_metric          \n",
      "    0      0.775294   0.695697   0.967739   1.251614  \n",
      "    1      0.745729   0.693529   0.967761   1.23867            \n",
      "    2      0.782739   0.687591   0.967807   1.243857           \n",
      "    3      0.797163   0.688202   0.967648   1.240897           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6882021198739805, 0.9676475022047587, 1.2408971842033665]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/10,1, wds=wd,cycle_len=4,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('512_SeResNext50_ph1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    }
   ],
   "source": [
    "learn.load('512_SeResNext50_ph1')\n",
    "pred = make_prediction()\n",
    "save_pred(pred, th_t, fname=f'protein_class_6_cyclic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10de9a4094d84be99f78cca371c78166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc        f1_metric          \n",
      "    0      0.728206   0.68791    0.967761   1.236777  \n",
      "    1      0.781594   0.686255   0.967727   1.241132           \n",
      "    2      0.723164   0.687543   0.968263   1.231486           \n",
      "    3      0.734272   0.683614   0.967898   1.231713           \n",
      "    4      0.732791   0.677931   0.968069   1.231907           \n",
      "    5      0.7298     0.675114   0.968183   1.226317           \n",
      "    6      0.718759   0.672941   0.968536   1.230101           \n",
      "    7      0.719348   0.674216   0.968468   1.221914           \n",
      "    8      0.750472   0.668775   0.968628   1.227721           \n",
      "    9      0.71544    0.668925   0.968707   1.227156           \n",
      "    10     0.71032    0.664461   0.968992   1.224632           \n",
      "    11     0.747331   0.668046   0.968673   1.222994           \n",
      "    12     0.687017   0.664117   0.968616   1.222007           \n",
      "    13     0.708986   0.662011   0.969061   1.222065           \n",
      "    14     0.749305   0.661583   0.968981   1.221199           \n",
      "    15     0.731544   0.661141   0.969232   1.219992           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6611414109169486, 0.9692315135552918, 1.2199920461523206]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/10,1, wds=wd,cycle_len=16,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('512_SeResNext50_ph2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dab6f6ff3d4957bc08b1ccdc763cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc        f1_metric          \n",
      "    0      0.727234   0.677654   0.968491   1.220745  \n",
      "    1      0.712676   0.673115   0.968138   1.225033           \n",
      "    2      0.691448   0.672338   0.968434   1.209406           \n",
      "    3      0.67181    0.682891   0.968924   1.196288           \n",
      "    4      0.702909   0.655203   0.969471   1.20603            \n",
      "    5      0.721483   0.638433   0.969972   1.209929           \n",
      "    6      0.625668   0.641593   0.970086   1.199806           \n",
      "    7      0.704184   0.633087   0.970063   1.208483           \n",
      "    8      0.632348   0.638117   0.970337   1.198934           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6381167059083158, 0.9703369013580001, 1.198934059806439]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/3,1, wds=wd,cycle_len=9,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    }
   ],
   "source": [
    "pred = make_prediction()\n",
    "save_pred(pred, th_t, fname=f'protein_class_6_cyclic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred = make_prediction()\n",
    "save_pred(pred, 0.5, fname=f'protein_class_6_0.5_cyclic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2b1a8f7cf24eeb97bc5620afccdc7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc        f1_metric          \n",
      "    0      0.772466   0.715455   0.967818   1.199894  \n",
      "    1      0.729953   0.709808   0.966098   1.205288           \n",
      " 55%|    | 1931/3492 [19:51<16:03,  1.62it/s, loss=0.675]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-dc444163189a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mIS_TORCH_04\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_params_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_params_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit(lrs,1, wds=wd,cycle_len=6,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('512_SeResNext50_ph3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next Schedule Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Increase the 256x256 number of epochs - can we get more out of this intermediary step?\n",
    "1. Increase the training rate of the 512x512 phase - can this learn faster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9th Nov - find best fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "wd = 1e-7\n",
    "lrs=np.array([lr/10,lr/3,lr])\n",
    "\n",
    "sz = 256\n",
    "bs = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(folds):\n",
    "    md = get_fold(sz,bs,k)\n",
    "    learn = get_resnext50_model(md)\n",
    "    learn.unfreeze()\n",
    "    learn.fit(lr, 1, wds=wd, cycle_len=10, use_clr_beta=(10,10,0.85,0.9), use_wd_sched=True)\n",
    "    learn.save(f'SEResNextFold_test_{k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train all folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cyclic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_model(sz, bs, k):\n",
    "    md = get_fold(sz,bs,k)\n",
    "    learn = get_resnext50_model(md)\n",
    "    learn.freeze_to(1)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "wd = 1e-7\n",
    "nw = 6\n",
    "lrs=np.array([lr/10,lr/3,lr])\n",
    "\n",
    "for k in range(folds):\n",
    "    # 128x128 phase\n",
    "    learn = get_fold_model(128, 24, k)\n",
    "    \n",
    "    learn.fit(lr,1,wds=wd,cycle_len=8,use_clr=(5,8))\n",
    "\n",
    "    learn.unfreeze()\n",
    "    learn.bn_freeze(True)\n",
    "\n",
    "    learn.fit(lrs/2, 1, wds=wd, cycle_len=10,use_clr=(20,10))\n",
    "\n",
    "    learn.save(f'128_SeResNext50_{k}')\n",
    "\n",
    "    # 256 x 256 phase\n",
    "    learn = get_fold_model(256, 16, k)\n",
    "    learn.load(f'128_SeResNext50_{k}')\n",
    "\n",
    "    learn.fit(lr,1,wds=wd, cycle_len=5,use_clr=(5,5))\n",
    "\n",
    "    learn.unfreeze()\n",
    "    learn.bn_freeze(True)\n",
    "\n",
    "    learn.fit(lrs/2,2,wds=wd, cycle_len=10,use_clr=(20,8))\n",
    "\n",
    "    learn.save(f'256_SeResNext50_{k}')\n",
    "\n",
    "    #512 x 512 phase\n",
    "    learn = get_fold_model(512, 8, k)\n",
    "    learn.load(f'256_SeResNext50_{k}')\n",
    "\n",
    "    learn.fit(lr,1, wds=wd, cycle_len=2,use_clr=(5,4))\n",
    "\n",
    "    learn.unfreeze()\n",
    "    learn.bn_freeze(True)\n",
    "\n",
    "    learn.fit(lrs/3, 2, wds=wd,cycle_len=16,use_clr=(20,8))\n",
    "    \n",
    "    learn.fit(lrs/8, 1, wds=wd,cycle_len=9,use_clr=(20,8))\n",
    "\n",
    "    learn.save(f'512_SeResNext50_ph1_{k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 1 Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "lrs=np.array([lr/10,lr/3,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845bcc6f99294d8d89b845b57baeed22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.561516   0.322511   0.983827  \n",
      "    1      0.50706    0.337665   0.982777                      \n",
      "    2      0.533345   0.333185   0.983008                      \n",
      "    3      0.509905   0.331454   0.983193                      \n",
      "    4      0.45943    0.335594   0.982823                      \n",
      "    5      0.480436   0.336579   0.982835                      \n",
      "    6      0.449071   0.338555   0.982489                      \n",
      "    7      0.449808   0.342649   0.982662                      \n",
      "    8      0.466516   0.335259   0.982847                      \n",
      "    9      0.424796   0.341782   0.9831                        \n",
      "    10     0.430926   0.331194   0.983666                      \n",
      "    11     0.451149   0.332387   0.983758                      \n",
      "    12     0.391414   0.360802   0.981993                      \n",
      "    13     0.411199   0.369752   0.982004                      \n",
      "    14     0.417081   0.373691   0.981416                      \n",
      "    15     0.430505   0.358323   0.982085                      \n",
      "    16     0.402487   0.37386    0.981797                      \n",
      "    17     0.383704   0.366073   0.981878                      \n",
      "    18     0.394063   0.38127    0.981947                      \n",
      "    19     0.381538   0.374348   0.982028                      \n",
      "    20     0.418004   0.37905    0.981924                      \n",
      "    21     0.377952   0.366091   0.982581                      \n",
      "    22     0.336216   0.377124   0.982489                      \n",
      "    23     0.337059   0.377441   0.982154                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a417b86dfc348e1ac96f8ccbbae4f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.364663   0.395059   0.981162  \n",
      "    1      0.401705   0.406237   0.981197                      \n",
      "    2      0.350917   0.406265   0.981993                      \n",
      "    3      0.374285   0.418444   0.98092                       \n",
      "    4      0.377207   0.423528   0.980886                      \n",
      "    5      0.39707    0.427128   0.981105                      \n",
      "    6      0.341997   0.415272   0.981255                      \n",
      "    7      0.296755   0.408026   0.981624                      \n",
      "    8      0.333297   0.417009   0.981866                      \n",
      "    9      0.311002   0.436773   0.981024                      \n",
      "    10     0.320172   0.428638   0.981393                      \n",
      "    11     0.324638   0.41876    0.98182                       \n",
      "    12     0.3252     0.449242   0.980909                      \n",
      "    13     0.330315   0.462604   0.979767                      \n",
      "    14     0.322214   0.462212   0.980632                      \n",
      "    15     0.323027   0.443239   0.98047                       \n",
      "    16     0.31658    0.467855   0.980966                      \n",
      "    17     0.277709   0.459426   0.980782                      \n",
      "    18     0.316399   0.467382   0.981185                      \n",
      "    19     0.309614   0.486346   0.981059                      \n",
      "    20     0.269693   0.48393    0.980943                      \n",
      "    21     0.269009   0.478648   0.981151                      \n",
      "    22     0.257742   0.483022   0.980736                      \n",
      "    23     0.247757   0.488501   0.980932                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7ea4a79a484071a9fd02c6930ff23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.246534   0.49259    0.980932  \n",
      "    1      0.235799   0.481788   0.98107                       \n",
      "    2      0.252157   0.509939   0.981001                      \n",
      "    3      0.235634   0.488389   0.981635                      \n",
      "    4      0.228024   0.496234   0.981035                      \n",
      "    5      0.257285   0.501558   0.980909                      \n",
      "    6      0.262154   0.50743    0.980989                      \n",
      "    7      0.249349   0.507028   0.980874                      \n",
      "    8      0.253412   0.512421   0.980862                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba03f8ba2244cdc8b19b6031ae66fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.230893   0.500597   0.980851  \n",
      "    1      0.211422   0.484886   0.981232                      \n",
      "    2      0.224332   0.533511   0.980516                      \n",
      "    3      0.237798   0.512704   0.981243                      \n",
      "    4      0.203887   0.520146   0.981139                      \n",
      "    5      0.24133    0.521694   0.980424                      \n",
      "    6      0.24196    0.511134   0.980862                      \n",
      "    7      0.251287   0.496899   0.981405                      \n",
      "    8      0.223016   0.533166   0.980724                      \n",
      "    9      0.224011   0.52775    0.981382                      \n",
      "    10     0.210874   0.53933    0.980493                      \n",
      "    11     0.208699   0.519941   0.981047                      \n",
      "                                                  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/eigenstir/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5094ac397a5a4923a290209cd6ee3839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   acc                           \n",
      "    0      0.534535   0.333124   0.982808  \n",
      "    1      0.517354   0.346239   0.982495                      \n",
      "    2      0.499761   0.346503   0.982115                      \n",
      "    3      0.505693   0.350163   0.982193                      \n",
      "    4      0.477361   0.345781   0.982327                      \n",
      "    5      0.483133   0.344059   0.982886                      \n",
      " 83%| | 2877/3484 [27:21<05:46,  1.75it/s, loss=0.441]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ff908956ea8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     learn.fit(lrs/4,2,\n\u001b[1;32m      9\u001b[0m               \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m               best_save_name=f'SEResNext50_{k}_{phase}_mfolds')\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mupdate_fp32_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in range(folds):\n",
    "    md = get_fold(sz,bs,k)\n",
    "    learn = get_resnext50_model(md)\n",
    "    learn.load(f'SEResNext50_Mk1_final')\n",
    "    learn.unfreeze()\n",
    "\n",
    "    phase=1\n",
    "    learn.fit(lrs/4,2,\n",
    "              cycle_len=12,use_clr=(10,20), \n",
    "              best_save_name=f'SEResNext50_{k}_{phase}_mfolds')\n",
    "\n",
    "    phase=2\n",
    "    learn.fit(lrs/4,2,\n",
    "              cycle_len=12,use_clr=(10,20), \n",
    "              best_save_name=f'SEResNext50_{k}_{phase}_mfolds')\n",
    "\n",
    "    phase=3\n",
    "    learn.fit(lrs/16,1,\n",
    "              cycle_len=9,use_clr=(5,20),\n",
    "              best_save_name=f'SEResNext50_{k}_{phase}_mfolds')\n",
    "    \n",
    "    phase=4\n",
    "    learn.fit(lrs/16,1,\n",
    "          cycle_len=12,use_clr=(5,20),\n",
    "          best_save_name=f'SEResNext50_{k}_{phase}_mfolds')\n",
    "\n",
    "    learn.save(f'SEResNext50_{k}_{phase}_mfolds_final')\n",
    "    \n",
    "    pred = make_prediction()\n",
    "    save_pred(pred, th_t, fname=f'protein_class_{k}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "def sigmoid_np(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "preds,y = learn.TTA(n_aug=16)\n",
    "preds = np.stack(preds, axis=-1)\n",
    "preds = sigmoid_np(preds)\n",
    "pred = preds.max(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def F1_soft(preds,targs,th=0.5,d=50.0):\n",
    "    preds = sigmoid_np(d*(preds - th))\n",
    "    targs = targs.astype(np.float)\n",
    "    score = 2.0*(preds*targs).sum(axis=0)/((preds+targs).sum(axis=0) + 1e-6)\n",
    "    return score\n",
    "\n",
    "def fit_val(x,y):\n",
    "    params = 0.5*np.ones(len(name_label_dict))\n",
    "    wd = 1e-5\n",
    "    error = lambda p: np.concatenate((F1_soft(x,y,p) - 1.0,\n",
    "                                      wd*(p - 0.5)), axis=None)\n",
    "    p, success = opt.leastsq(error, params)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds:  [0.67447 0.77441 0.6432  0.71032 0.7633  0.58246 0.59099 0.61067 0.59715 0.83648 0.47122 0.71517 0.73005\n",
      " 0.91396 0.72482 0.44042 0.88081 0.75626 0.519   0.60685 0.80563 0.61776 0.75221 0.76512 0.74962 0.60664\n",
      " 0.71887 0.63454]\n",
      "F1 macro:  0.7140915172064203\n",
      "F1 macro (th = 0.5):  0.6832496715576231\n",
      "F1 micro:  0.7769354338697405\n"
     ]
    }
   ],
   "source": [
    "th = fit_val(pred,y)\n",
    "th[th<0.1] = 0.1\n",
    "print('Thresholds: ',th)\n",
    "print('F1 macro: ',f1_score(y, pred>th, average='macro'))\n",
    "print('F1 macro (th = 0.5): ',f1_score(y, pred>0.5, average='macro'))\n",
    "print('F1 micro: ',f1_score(y, pred>th, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractions:  [0.43182 0.04031 0.11328 0.04902 0.05763 0.08668 0.0318  0.08782 0.00265 0.00104 0.00104 0.0318  0.02347\n",
      " 0.01722 0.037   0.00123 0.0158  0.00823 0.03341 0.04325 0.00729 0.12416 0.02697 0.0987  0.00833 0.30803\n",
      " 0.01306 0.00028]\n",
      "Fractions (true):  [0.41355 0.04154 0.11772 0.05139 0.06057 0.08167 0.03322 0.09217 0.00199 0.00151 0.00095 0.03615 0.02423\n",
      " 0.01845 0.03511 0.00076 0.01902 0.00757 0.03    0.04902 0.00577 0.12321 0.02725 0.09577 0.01107 0.26517\n",
      " 0.01107 0.00066]\n"
     ]
    }
   ],
   "source": [
    "print('Fractions: ',(pred > th).mean(axis=0))\n",
    "print('Fractions (true): ',(y > th).mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractions:  [0.46804 0.04478 0.09306 0.03786 0.05264 0.0746  0.02991 0.07375 0.00154 0.00111 0.00051 0.03717 0.03179\n",
      " 0.0282  0.05042 0.00009 0.03837 0.02239 0.02589 0.03965 0.00667 0.15023 0.03076 0.11152 0.00872 0.35208\n",
      " 0.02042 0.00077]\n"
     ]
    }
   ],
   "source": [
    "th_t = np.array([0.565,0.39,0.55,0.345,0.33,0.39,0.33,0.45,0.38,0.39,\n",
    "               0.34,0.42,0.31,0.38,0.49,0.50,0.38,0.43,0.46,0.40,\n",
    "               0.39,0.505,0.37,0.47,0.41,0.545,0.32,0.1])\n",
    "print('Fractions: ',(pred_t > th_t).mean(axis=0))\n",
    "save_pred(pred_t,th_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "preds_t,y_t = learn.TTA(n_aug=16,is_test=True)\n",
    "preds_t = np.stack(preds_t, axis=-1)\n",
    "preds_t = sigmoid_np(preds_t)\n",
    "pred_t = preds_t.max(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_prob = [\n",
    " 0.362397820,0.043841336,0.075268817,0.059322034,0.075268817,\n",
    " 0.075268817,0.043841336,0.075268817,0.010000000,0.010000000,\n",
    " 0.010000000,0.043841336,0.043841336,0.014198783,0.043841336,\n",
    " 0.010000000,0.028806584,0.014198783,0.028806584,0.059322034,\n",
    " 0.010000000,0.126126126,0.028806584,0.075268817,0.010000000,\n",
    " 0.222493880,0.028806584,0.010000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Count_soft(preds,th=0.5,d=50.0):\n",
    "    preds = sigmoid_np(d*(preds - th))\n",
    "    return preds.mean(axis=0)\n",
    "\n",
    "def fit_test(x,y):\n",
    "    params = 0.5*np.ones(len(name_label_dict))\n",
    "    wd = 1e-5\n",
    "    error = lambda p: np.concatenate((Count_soft(x,p) - y,\n",
    "                                      wd*(p - 0.5)), axis=None)\n",
    "    p, success = opt.leastsq(error, params)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds:  [0.80374 0.49925 0.76483 0.21822 0.24233 0.49543 0.26365 0.54937 0.10824 0.1054  0.1     0.42081 0.25919\n",
      " 0.89889 0.77842 0.1     0.69168 0.86501 0.56459 0.292   0.35843 0.70467 0.5345  0.81766 0.45866 0.80764\n",
      " 0.27445 0.1    ]\n",
      "Fractions:  [0.36361 0.04384 0.07546 0.05871 0.07426 0.0752  0.0435  0.07503 0.00461 0.00419 0.00171 0.04392 0.04341\n",
      " 0.01461 0.04384 0.00205 0.0288  0.01461 0.02888 0.05922 0.01008 0.1269  0.02888 0.0758  0.01    0.22466\n",
      " 0.0288  0.00137]\n",
      "Fractions (th = 0.5):  [0.52777 0.04384 0.11571 0.0382  0.04974 0.07469 0.02512 0.08067 0.00162 0.00103 0.00068 0.03991 0.02863\n",
      " 0.0282  0.05461 0.00009 0.03863 0.02495 0.03179 0.04187 0.00795 0.17886 0.02991 0.1275  0.00974 0.41386\n",
      " 0.01846 0.00009]\n"
     ]
    }
   ],
   "source": [
    "th_t = fit_test(pred_t,lb_prob)\n",
    "th_t[th_t<0.1] = 0.1\n",
    "print('Thresholds: ',th_t)\n",
    "print('Fractions: ',(pred_t > th_t).mean(axis=0))\n",
    "print('Fractions (th = 0.5): ',(pred_t > 0.5).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pred(pred_t,th_t,'protein_classification_f.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pred(pred_t,th,'protein_classification_v.csv')\n",
    "save_pred(pred_t,0.5,'protein_classification_05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [8,9,10,15,20,24,27]\n",
    "for i in class_list:\n",
    "    th_t[i] = th[i]\n",
    "save_pred(pred_t,th_t,'protein_classification_c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([12885.,  1254.,  3621.,  1561.,  1858.,  2513.,  1008.,  2822.,    53.,    45.,    28.,  1093.,\n",
       "          688.,   537.,  1066.,    21.,   530.,   210.,   902.,  1482.,   172.,  3777.,   802.,  2965.,\n",
       "          322.,  8228.,   328.,    11.]),\n",
       " array([0.41468, 0.04036, 0.11654, 0.05024, 0.0598 , 0.08088, 0.03244, 0.09082, 0.00171, 0.00145, 0.0009 ,\n",
       "        0.03518, 0.02214, 0.01728, 0.03431, 0.00068, 0.01706, 0.00676, 0.02903, 0.0477 , 0.00554, 0.12156,\n",
       "        0.02581, 0.09542, 0.01036, 0.2648 , 0.01056, 0.00035]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(LABELS).set_index('Id')\n",
    "label_count = np.zeros(len(name_label_dict))\n",
    "for label in labels['Target']:\n",
    "    l = [int(i) for i in label.split()]\n",
    "    label_count += np.eye(len(name_label_dict))[l].sum(axis=0)\n",
    "label_fraction = label_count.astype(np.float)/len(labels)\n",
    "label_count, label_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds:  [0.7347  0.56408 0.50024 0.30176 0.36257 0.45713 0.37413 0.41914 0.50788 0.35831 0.2295  0.57945 0.64883\n",
      " 0.80423 0.91007 0.24861 0.91427 0.97507 0.55993 0.41841 0.70555 0.72181 0.60697 0.7074  0.41463 0.76006\n",
      " 0.84881 0.27531]\n",
      "Fractions:  [0.41736 0.04008 0.11562 0.04982 0.05931 0.08041 0.0317  0.09075 0.00162 0.00137 0.00085 0.03512 0.02196\n",
      " 0.01718 0.03563 0.0006  0.01718 0.00829 0.02897 0.0482  0.00547 0.12177 0.02615 0.0958  0.01025 0.26782\n",
      " 0.01051 0.00034]\n"
     ]
    }
   ],
   "source": [
    "th_t = fit_test(pred_t,label_fraction)\n",
    "th_t[th_t<0.05] = 0.05\n",
    "print('Thresholds: ',th_t)\n",
    "print('Fractions: ',(pred_t > th_t).mean(axis=0))\n",
    "save_pred(pred_t,th_t,'protein_classification_t.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Folds Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/SEResNext50_0_final.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5d966fb219d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'SEResNext50_{k}_final'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpreds_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTTA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpreds_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'swa_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-swa.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/torch_imports.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(m, p)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/SEResNext50_0_final.h5'"
     ]
    }
   ],
   "source": [
    "pred_array = np.zeros((11702, 28),dtype=float)\n",
    "\n",
    "for k in range(folds):\n",
    "    learn.load(f'SEResNext50_{k}_final')\n",
    "    preds_t,y_t = learn.TTA(n_aug=8, is_test=True)\n",
    "    preds_t = np.stack(preds_t, axis=-1)\n",
    "    preds_t = sigmoid_np(preds_t)\n",
    "    pred_t = preds_t.max(axis=-1)\n",
    "    pred_array = pred_t + pred_array\n",
    "\n",
    "pred_array = pred_array / folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_t = np.array([0.565,0.39,0.55,0.345,0.33,0.39,0.33,0.45,0.38,0.39,\n",
    "               0.34,0.42,0.31,0.38,0.49,0.50,0.38,0.43,0.46,0.40,\n",
    "               0.39,0.505,0.37,0.47,0.41,0.545,0.32,0.1])\n",
    "(pred_array > th_t).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pred(pred_array,th_t,'protein_classification_mfolds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_list = []\n",
    "# for line in pred_array:\n",
    "#     s = ' '.join(list([str(i) for i in np.nonzero(line>th_t)[0]]))\n",
    "#     pred_list.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df = pd.read_csv(SAMPLE)\n",
    "# sample_list = list(sample_df.Id)\n",
    "# pred_dic = dict((key, value) for (key, value) \n",
    "#                 in zip(learn.data.test_ds.fnames,pred_list))\n",
    "# pred_list_cor = [pred_dic[id] for id in sample_list]\n",
    "# df = pd.DataFrame({'Id':sample_list,'Predicted':pred_list_cor})\n",
    "# df.to_csv('protein_classification.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 (pretrained)\n",
    "1. lr=1e-2\n",
    "1. learn.fit(lrs/4,4,cycle_len=2,use_clr=(10,20), best_save_name=f'{arch}_{phase}')\n",
    "1. learn.fit(lrs/4,2,cycle_len=23,use_clr=(10,20), best_save_name=f'{arch}_{phase}')\n",
    "1. learn.fit(lrs/8,1,cycle_len=10,use_clr=(5,20), best_save_name=f'{arch}_{phase}')\n",
    "\n",
    "LB Score: 0.50 (modelname:<function resnet50 at 0x7f41f50d3400> _3), \n",
    "\n",
    "Resnet50 - 0.7056019664330974 0.6823389611938516, LB:0.503\n",
    "\n",
    "SEResNext50\n",
    "1. lr=1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other ideas\n",
    "1. Set gradient clipping to 1.0 instead of 0.25\n",
    "1. Try another Focal Loss implementation\n",
    "1. Increase batch size - bs=8 so far means 7GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def _init_(self, num_classes=28):\n",
    "        super()._init_()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, pred, targ):\n",
    "        t = targ\n",
    "        x = pred\n",
    "        w = self.get_weight(x,t)\n",
    "        return F.binary_cross_entropy_with_logits(x, t, w, \n",
    "                          size_average=False)/self.num_classes\n",
    "    \n",
    "    def get_weight(self,x,t):\n",
    "        alpha,gamma = 0.25,2.\n",
    "        p = x.sigmoid()\n",
    "        pt = p*t + (1-p)*(1-t)\n",
    "        w = alpha*t + (1-alpha)*(1-t)\n",
    "        return w * (1-pt).pow(gamma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
